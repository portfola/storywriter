This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.gitignore
android/.gitignore
android/app/build.gradle
android/app/proguard-rules.pro
android/app/src/debug/AndroidManifest.xml
android/app/src/main/AndroidManifest.xml
android/app/src/main/java/com/portfola/StoryWriter/MainActivity.kt
android/app/src/main/java/com/portfola/StoryWriter/MainApplication.kt
android/app/src/main/res/drawable/ic_launcher_background.xml
android/app/src/main/res/drawable/rn_edit_text_material.xml
android/app/src/main/res/mipmap-anydpi-v26/ic_launcher_round.xml
android/app/src/main/res/mipmap-anydpi-v26/ic_launcher.xml
android/app/src/main/res/values-night/colors.xml
android/app/src/main/res/values/colors.xml
android/app/src/main/res/values/strings.xml
android/app/src/main/res/values/styles.xml
android/build.gradle
android/gradle.properties
android/gradle/wrapper/gradle-wrapper.properties
android/gradlew
android/gradlew.bat
android/settings.gradle
app.config.js
app/_layout.tsx
app/+not-found.tsx
app/index.tsx
app/story-original.tsx
app/story.tsx
babel.config.js
components/__tests__/__snapshots__/ThemedText-test.tsx.snap
components/__tests__/ThemedText-test.tsx
components/Collapsible.tsx
components/ExternalLink.tsx
components/HelloWave.tsx
components/navigation/TabBarIcon.tsx
components/ParallaxScrollView.tsx
components/QuestionArea.tsx
components/screens/WelcomeScreen.tsx
components/SpeechControls.tsx
components/StoryDisplay.tsx
components/StoryManagement.tsx
components/ThemedText.tsx
components/ThemedView.tsx
components/VoiceWave.tsx
constants/Colors.ts
eas.json
hooks/useColorScheme.ts
hooks/useColorScheme.web.ts
hooks/usePolly.ts
hooks/useThemeColor.ts
package.json
README.md
scripts/reset-project.js
services/huggingFaceService.js
services/polly/index.ts
services/polly/native.ts
services/polly/polly-wrapper.ts
services/polly/types.ts
services/polly/web.ts
services/transcribe/index.ts
services/transcribe/native.ts
services/transcribe/types.ts
services/transcribe/web.ts
src/data/storyData.ts
src/stores/conversationStore.ts
src/utils/storyGenerator.ts
tsconfig.json
types/env.d.ts

================================================================
Files
================================================================

================
File: .gitignore
================
node_modules/
.expo/
dist/
npm-debug.*
*.jks
*.p8
*.p12
*.key
*.mobileprovision
*.orig.*
web-build/
.env

# macOS
.DS_Store

# packages
package-lock.json

================
File: android/.gitignore
================
# OSX
#
.DS_Store

# Android/IntelliJ
#
build/
.idea
.gradle
local.properties
*.iml
*.hprof
.cxx/

# Bundle artifacts
*.jsbundle

================
File: android/app/build.gradle
================
apply plugin: "com.android.application"
apply plugin: "org.jetbrains.kotlin.android"
apply plugin: "com.facebook.react"

def projectRoot = rootDir.getAbsoluteFile().getParentFile().getAbsolutePath()

/**
 * This is the configuration block to customize your React Native Android app.
 * By default you don't need to apply any configuration, just uncomment the lines you need.
 */
react {
    entryFile = file(["node", "-e", "require('expo/scripts/resolveAppEntry')", projectRoot, "android", "absolute"].execute(null, rootDir).text.trim())
    reactNativeDir = new File(["node", "--print", "require.resolve('react-native/package.json')"].execute(null, rootDir).text.trim()).getParentFile().getAbsoluteFile()
    hermesCommand = new File(["node", "--print", "require.resolve('react-native/package.json')"].execute(null, rootDir).text.trim()).getParentFile().getAbsolutePath() + "/sdks/hermesc/%OS-BIN%/hermesc"
    codegenDir = new File(["node", "--print", "require.resolve('@react-native/codegen/package.json', { paths: [require.resolve('react-native/package.json')] })"].execute(null, rootDir).text.trim()).getParentFile().getAbsoluteFile()

    // Use Expo CLI to bundle the app, this ensures the Metro config
    // works correctly with Expo projects.
    cliFile = new File(["node", "--print", "require.resolve('@expo/cli', { paths: [require.resolve('expo/package.json')] })"].execute(null, rootDir).text.trim())
    bundleCommand = "export:embed"

    /* Folders */
     //   The root of your project, i.e. where "package.json" lives. Default is '../..'
    // root = file("../../")
    //   The folder where the react-native NPM package is. Default is ../../node_modules/react-native
    // reactNativeDir = file("../../node_modules/react-native")
    //   The folder where the react-native Codegen package is. Default is ../../node_modules/@react-native/codegen
    // codegenDir = file("../../node_modules/@react-native/codegen")

    /* Variants */
    //   The list of variants to that are debuggable. For those we're going to
    //   skip the bundling of the JS bundle and the assets. By default is just 'debug'.
    //   If you add flavors like lite, prod, etc. you'll have to list your debuggableVariants.
    // debuggableVariants = ["liteDebug", "prodDebug"]

    /* Bundling */
    //   A list containing the node command and its flags. Default is just 'node'.
    // nodeExecutableAndArgs = ["node"]

    //
    //   The path to the CLI configuration file. Default is empty.
    // bundleConfig = file(../rn-cli.config.js)
    //
    //   The name of the generated asset file containing your JS bundle
    // bundleAssetName = "MyApplication.android.bundle"
    //
    //   The entry file for bundle generation. Default is 'index.android.js' or 'index.js'
    // entryFile = file("../js/MyApplication.android.js")
    //
    //   A list of extra flags to pass to the 'bundle' commands.
    //   See https://github.com/react-native-community/cli/blob/main/docs/commands.md#bundle
    // extraPackagerArgs = []

    /* Hermes Commands */
    //   The hermes compiler command to run. By default it is 'hermesc'
    // hermesCommand = "$rootDir/my-custom-hermesc/bin/hermesc"
    //
    //   The list of flags to pass to the Hermes compiler. By default is "-O", "-output-source-map"
    // hermesFlags = ["-O", "-output-source-map"]

    /* Autolinking */
    autolinkLibrariesWithApp()
}

/**
 * Set this to true to Run Proguard on Release builds to minify the Java bytecode.
 */
def enableProguardInReleaseBuilds = (findProperty('android.enableProguardInReleaseBuilds') ?: false).toBoolean()

/**
 * The preferred build flavor of JavaScriptCore (JSC)
 *
 * For example, to use the international variant, you can use:
 * `def jscFlavor = 'org.webkit:android-jsc-intl:+'`
 *
 * The international variant includes ICU i18n library and necessary data
 * allowing to use e.g. `Date.toLocaleString` and `String.localeCompare` that
 * give correct results when using with locales other than en-US. Note that
 * this variant is about 6MiB larger per architecture than default.
 */
def jscFlavor = 'org.webkit:android-jsc:+'

android {
    ndkVersion rootProject.ext.ndkVersion

    buildToolsVersion rootProject.ext.buildToolsVersion
    compileSdk rootProject.ext.compileSdkVersion

    namespace 'com.portfola.StoryWriter'
    defaultConfig {
        applicationId 'com.portfola.StoryWriter'
        minSdkVersion rootProject.ext.minSdkVersion
        targetSdkVersion rootProject.ext.targetSdkVersion
        versionCode 1
        versionName "1.0.0"
    }
    signingConfigs {
        debug {
            storeFile file('debug.keystore')
            storePassword 'android'
            keyAlias 'androiddebugkey'
            keyPassword 'android'
        }
    }
    buildTypes {
        debug {
            signingConfig signingConfigs.debug
        }
        release {
            // Caution! In production, you need to generate your own keystore file.
            // see https://reactnative.dev/docs/signed-apk-android.
            signingConfig signingConfigs.debug
            shrinkResources (findProperty('android.enableShrinkResourcesInReleaseBuilds')?.toBoolean() ?: false)
            minifyEnabled enableProguardInReleaseBuilds
            proguardFiles getDefaultProguardFile("proguard-android.txt"), "proguard-rules.pro"
            crunchPngs (findProperty('android.enablePngCrunchInReleaseBuilds')?.toBoolean() ?: true)
        }
    }
    packagingOptions {
        jniLibs {
            useLegacyPackaging (findProperty('expo.useLegacyPackaging')?.toBoolean() ?: false)
        }
    }
    androidResources {
        ignoreAssetsPattern '!.svn:!.git:!.ds_store:!*.scc:!CVS:!thumbs.db:!picasa.ini:!*~'
    }
}

// Apply static values from `gradle.properties` to the `android.packagingOptions`
// Accepts values in comma delimited lists, example:
// android.packagingOptions.pickFirsts=/LICENSE,**/picasa.ini
["pickFirsts", "excludes", "merges", "doNotStrip"].each { prop ->
    // Split option: 'foo,bar' -> ['foo', 'bar']
    def options = (findProperty("android.packagingOptions.$prop") ?: "").split(",");
    // Trim all elements in place.
    for (i in 0..<options.size()) options[i] = options[i].trim();
    // `[] - ""` is essentially `[""].filter(Boolean)` removing all empty strings.
    options -= ""

    if (options.length > 0) {
        println "android.packagingOptions.$prop += $options ($options.length)"
        // Ex: android.packagingOptions.pickFirsts += '**/SCCS/**'
        options.each {
            android.packagingOptions[prop] += it
        }
    }
}

dependencies {
    // The version of react-native is set by the React Native Gradle Plugin
    implementation("com.facebook.react:react-android")

    def isGifEnabled = (findProperty('expo.gif.enabled') ?: "") == "true";
    def isWebpEnabled = (findProperty('expo.webp.enabled') ?: "") == "true";
    def isWebpAnimatedEnabled = (findProperty('expo.webp.animated') ?: "") == "true";

    if (isGifEnabled) {
        // For animated gif support
        implementation("com.facebook.fresco:animated-gif:${reactAndroidLibs.versions.fresco.get()}")
    }

    if (isWebpEnabled) {
        // For webp support
        implementation("com.facebook.fresco:webpsupport:${reactAndroidLibs.versions.fresco.get()}")
        if (isWebpAnimatedEnabled) {
            // Animated webp support
            implementation("com.facebook.fresco:animated-webp:${reactAndroidLibs.versions.fresco.get()}")
        }
    }

    if (hermesEnabled.toBoolean()) {
        implementation("com.facebook.react:hermes-android")
    } else {
        implementation jscFlavor
    }
}

================
File: android/app/proguard-rules.pro
================
# Add project specific ProGuard rules here.
# By default, the flags in this file are appended to flags specified
# in /usr/local/Cellar/android-sdk/24.3.3/tools/proguard/proguard-android.txt
# You can edit the include path and order by changing the proguardFiles
# directive in build.gradle.
#
# For more details, see
#   http://developer.android.com/guide/developing/tools/proguard.html

# react-native-reanimated
-keep class com.swmansion.reanimated.** { *; }
-keep class com.facebook.react.turbomodule.** { *; }

# Add any project specific keep options here:

================
File: android/app/src/debug/AndroidManifest.xml
================
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:tools="http://schemas.android.com/tools">

    <uses-permission android:name="android.permission.SYSTEM_ALERT_WINDOW"/>

    <application android:usesCleartextTraffic="true" tools:targetApi="28" tools:ignore="GoogleAppIndexingWarning" tools:replace="android:usesCleartextTraffic" />
</manifest>

================
File: android/app/src/main/AndroidManifest.xml
================
<manifest xmlns:android="http://schemas.android.com/apk/res/android">
  <uses-permission android:name="android.permission.INTERNET"/>
  <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/>
  <uses-permission android:name="android.permission.RECORD_AUDIO"/>
  <uses-permission android:name="android.permission.SYSTEM_ALERT_WINDOW"/>
  <uses-permission android:name="android.permission.VIBRATE"/>
  <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
  <queries>
    <intent>
      <action android:name="android.intent.action.VIEW"/>
      <category android:name="android.intent.category.BROWSABLE"/>
      <data android:scheme="https"/>
    </intent>
  </queries>
  <application android:name=".MainApplication" android:label="@string/app_name" android:icon="@mipmap/ic_launcher" android:roundIcon="@mipmap/ic_launcher_round" android:allowBackup="true" android:theme="@style/AppTheme" android:supportsRtl="true">
    <meta-data android:name="expo.modules.updates.ENABLED" android:value="false"/>
    <meta-data android:name="expo.modules.updates.EXPO_UPDATES_CHECK_ON_LAUNCH" android:value="ALWAYS"/>
    <meta-data android:name="expo.modules.updates.EXPO_UPDATES_LAUNCH_WAIT_MS" android:value="0"/>
    <activity android:name=".MainActivity" android:configChanges="keyboard|keyboardHidden|orientation|screenSize|screenLayout|uiMode" android:launchMode="singleTask" android:windowSoftInputMode="adjustResize" android:theme="@style/Theme.App.SplashScreen" android:exported="true" android:screenOrientation="landscape">
      <intent-filter>
        <action android:name="android.intent.action.MAIN"/>
        <category android:name="android.intent.category.LAUNCHER"/>
      </intent-filter>
      <intent-filter>
        <action android:name="android.intent.action.VIEW"/>
        <category android:name="android.intent.category.DEFAULT"/>
        <category android:name="android.intent.category.BROWSABLE"/>
        <data android:scheme="storywriter"/>
        <data android:scheme="com.portfola.StoryWriter"/>
        <data android:scheme="exp+storywriter"/>
      </intent-filter>
    </activity>
  </application>
</manifest>

================
File: android/app/src/main/java/com/portfola/StoryWriter/MainActivity.kt
================
package com.portfola.StoryWriter
import expo.modules.splashscreen.SplashScreenManager

import android.os.Build
import android.os.Bundle

import com.facebook.react.ReactActivity
import com.facebook.react.ReactActivityDelegate
import com.facebook.react.defaults.DefaultNewArchitectureEntryPoint.fabricEnabled
import com.facebook.react.defaults.DefaultReactActivityDelegate

import expo.modules.ReactActivityDelegateWrapper

class MainActivity : ReactActivity() {
  override fun onCreate(savedInstanceState: Bundle?) {
    // Set the theme to AppTheme BEFORE onCreate to support
    // coloring the background, status bar, and navigation bar.
    // This is required for expo-splash-screen.
    // setTheme(R.style.AppTheme);
    // @generated begin expo-splashscreen - expo prebuild (DO NOT MODIFY) sync-f3ff59a738c56c9a6119210cb55f0b613eb8b6af
    SplashScreenManager.registerOnActivity(this)
    // @generated end expo-splashscreen
    super.onCreate(null)
  }

  /**
   * Returns the name of the main component registered from JavaScript. This is used to schedule
   * rendering of the component.
   */
  override fun getMainComponentName(): String = "main"

  /**
   * Returns the instance of the [ReactActivityDelegate]. We use [DefaultReactActivityDelegate]
   * which allows you to enable New Architecture with a single boolean flags [fabricEnabled]
   */
  override fun createReactActivityDelegate(): ReactActivityDelegate {
    return ReactActivityDelegateWrapper(
          this,
          BuildConfig.IS_NEW_ARCHITECTURE_ENABLED,
          object : DefaultReactActivityDelegate(
              this,
              mainComponentName,
              fabricEnabled
          ){})
  }

  /**
    * Align the back button behavior with Android S
    * where moving root activities to background instead of finishing activities.
    * @see <a href="https://developer.android.com/reference/android/app/Activity#onBackPressed()">onBackPressed</a>
    */
  override fun invokeDefaultOnBackPressed() {
      if (Build.VERSION.SDK_INT <= Build.VERSION_CODES.R) {
          if (!moveTaskToBack(false)) {
              // For non-root activities, use the default implementation to finish them.
              super.invokeDefaultOnBackPressed()
          }
          return
      }

      // Use the default back button implementation on Android S
      // because it's doing more than [Activity.moveTaskToBack] in fact.
      super.invokeDefaultOnBackPressed()
  }
}

================
File: android/app/src/main/java/com/portfola/StoryWriter/MainApplication.kt
================
package com.portfola.StoryWriter

import android.app.Application
import android.content.res.Configuration

import com.facebook.react.PackageList
import com.facebook.react.ReactApplication
import com.facebook.react.ReactNativeHost
import com.facebook.react.ReactPackage
import com.facebook.react.ReactHost
import com.facebook.react.defaults.DefaultNewArchitectureEntryPoint.load
import com.facebook.react.defaults.DefaultReactNativeHost
import com.facebook.react.soloader.OpenSourceMergedSoMapping
import com.facebook.soloader.SoLoader

import expo.modules.ApplicationLifecycleDispatcher
import expo.modules.ReactNativeHostWrapper

class MainApplication : Application(), ReactApplication {

  override val reactNativeHost: ReactNativeHost = ReactNativeHostWrapper(
        this,
        object : DefaultReactNativeHost(this) {
          override fun getPackages(): List<ReactPackage> {
            val packages = PackageList(this).packages
            // Packages that cannot be autolinked yet can be added manually here, for example:
            // packages.add(new MyReactNativePackage());
            return packages
          }

          override fun getJSMainModuleName(): String = ".expo/.virtual-metro-entry"

          override fun getUseDeveloperSupport(): Boolean = BuildConfig.DEBUG

          override val isNewArchEnabled: Boolean = BuildConfig.IS_NEW_ARCHITECTURE_ENABLED
          override val isHermesEnabled: Boolean = BuildConfig.IS_HERMES_ENABLED
      }
  )

  override val reactHost: ReactHost
    get() = ReactNativeHostWrapper.createReactHost(applicationContext, reactNativeHost)

  override fun onCreate() {
    super.onCreate()
    SoLoader.init(this, OpenSourceMergedSoMapping)
    if (BuildConfig.IS_NEW_ARCHITECTURE_ENABLED) {
      // If you opted-in for the New Architecture, we load the native entry point for this app.
      load()
    }
    ApplicationLifecycleDispatcher.onApplicationCreate(this)
  }

  override fun onConfigurationChanged(newConfig: Configuration) {
    super.onConfigurationChanged(newConfig)
    ApplicationLifecycleDispatcher.onConfigurationChanged(this, newConfig)
  }
}

================
File: android/app/src/main/res/drawable/ic_launcher_background.xml
================
<layer-list xmlns:android="http://schemas.android.com/apk/res/android">
  <item android:drawable="@color/splashscreen_background"/>
  <item>
    <bitmap android:gravity="center" android:src="@drawable/splashscreen_logo"/>
  </item>
</layer-list>

================
File: android/app/src/main/res/drawable/rn_edit_text_material.xml
================
<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright (C) 2014 The Android Open Source Project

     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
-->
<inset xmlns:android="http://schemas.android.com/apk/res/android"
       android:insetLeft="@dimen/abc_edit_text_inset_horizontal_material"
       android:insetRight="@dimen/abc_edit_text_inset_horizontal_material"
       android:insetTop="@dimen/abc_edit_text_inset_top_material"
       android:insetBottom="@dimen/abc_edit_text_inset_bottom_material"
       >

    <selector>
        <!--
          This file is a copy of abc_edit_text_material (https://bit.ly/3k8fX7I).
          The item below with state_pressed="false" and state_focused="false" causes a NullPointerException.
          NullPointerException:tempt to invoke virtual method 'android.graphics.drawable.Drawable android.graphics.drawable.Drawable$ConstantState.newDrawable(android.content.res.Resources)'

          <item android:state_pressed="false" android:state_focused="false" android:drawable="@drawable/abc_textfield_default_mtrl_alpha"/>

          For more info, see https://bit.ly/3CdLStv (react-native/pull/29452) and https://bit.ly/3nxOMoR.
        -->
        <item android:state_enabled="false" android:drawable="@drawable/abc_textfield_default_mtrl_alpha"/>
        <item android:drawable="@drawable/abc_textfield_activated_mtrl_alpha"/>
    </selector>

</inset>

================
File: android/app/src/main/res/mipmap-anydpi-v26/ic_launcher_round.xml
================
<?xml version="1.0" encoding="utf-8"?>
<adaptive-icon xmlns:android="http://schemas.android.com/apk/res/android">
    <background android:drawable="@color/iconBackground"/>
    <foreground android:drawable="@mipmap/ic_launcher_foreground"/>
</adaptive-icon>

================
File: android/app/src/main/res/mipmap-anydpi-v26/ic_launcher.xml
================
<?xml version="1.0" encoding="utf-8"?>
<adaptive-icon xmlns:android="http://schemas.android.com/apk/res/android">
    <background android:drawable="@color/iconBackground"/>
    <foreground android:drawable="@mipmap/ic_launcher_foreground"/>
</adaptive-icon>

================
File: android/app/src/main/res/values-night/colors.xml
================
<resources/>

================
File: android/app/src/main/res/values/colors.xml
================
<resources>
  <color name="splashscreen_background">#ffffff</color>
  <color name="iconBackground">#ffffff</color>
  <color name="colorPrimary">#023c69</color>
  <color name="colorPrimaryDark">#ffffff</color>
</resources>

================
File: android/app/src/main/res/values/strings.xml
================
<resources>
  <string name="app_name">StoryWriter</string>
  <string name="expo_splash_screen_resize_mode" translatable="false">contain</string>
  <string name="expo_splash_screen_status_bar_translucent" translatable="false">false</string>
</resources>

================
File: android/app/src/main/res/values/styles.xml
================
<resources xmlns:tools="http://schemas.android.com/tools">
  <style name="AppTheme" parent="Theme.AppCompat.Light.NoActionBar">
    <item name="android:textColor">@android:color/black</item>
    <item name="android:editTextStyle">@style/ResetEditText</item>
    <item name="android:editTextBackground">@drawable/rn_edit_text_material</item>
    <item name="colorPrimary">@color/colorPrimary</item>
    <item name="android:statusBarColor">#ffffff</item>
  </style>
  <style name="ResetEditText" parent="@android:style/Widget.EditText">
    <item name="android:padding">0dp</item>
    <item name="android:textColorHint">#c8c8c8</item>
    <item name="android:textColor">@android:color/black</item>
  </style>
  <style name="Theme.App.SplashScreen" parent="Theme.SplashScreen">
    <item name="windowSplashScreenBackground">@color/splashscreen_background</item>
    <item name="windowSplashScreenAnimatedIcon">@drawable/splashscreen_logo</item>
    <item name="postSplashScreenTheme">@style/AppTheme</item>
  </style>
</resources>

================
File: android/build.gradle
================
// Top-level build file where you can add configuration options common to all sub-projects/modules.

buildscript {
    ext {
        buildToolsVersion = findProperty('android.buildToolsVersion') ?: '35.0.0'
        minSdkVersion = Integer.parseInt(findProperty('android.minSdkVersion') ?: '24')
        compileSdkVersion = Integer.parseInt(findProperty('android.compileSdkVersion') ?: '35')
        targetSdkVersion = Integer.parseInt(findProperty('android.targetSdkVersion') ?: '34')
        kotlinVersion = findProperty('android.kotlinVersion') ?: '1.9.24'

        ndkVersion = "26.1.10909125"
    }
    repositories {
        google()
        mavenCentral()
    }
    dependencies {
        classpath('com.android.tools.build:gradle')
        classpath('com.facebook.react:react-native-gradle-plugin')
        classpath('org.jetbrains.kotlin:kotlin-gradle-plugin')
    }
}

apply plugin: "com.facebook.react.rootproject"

allprojects {
    repositories {
        maven {
            // All of React Native (JS, Obj-C sources, Android binaries) is installed from npm
            url(new File(['node', '--print', "require.resolve('react-native/package.json')"].execute(null, rootDir).text.trim(), '../android'))
        }
        maven {
            // Android JSC is installed from npm
            url(new File(['node', '--print', "require.resolve('jsc-android/package.json', { paths: [require.resolve('react-native/package.json')] })"].execute(null, rootDir).text.trim(), '../dist'))
        }

        google()
        mavenCentral()
        maven { url 'https://www.jitpack.io' }
    }
}

================
File: android/gradle.properties
================
# Project-wide Gradle settings.

# IDE (e.g. Android Studio) users:
# Gradle settings configured through the IDE *will override*
# any settings specified in this file.

# For more details on how to configure your build environment visit
# http://www.gradle.org/docs/current/userguide/build_environment.html

# Specifies the JVM arguments used for the daemon process.
# The setting is particularly useful for tweaking memory settings.
# Default value: -Xmx512m -XX:MaxMetaspaceSize=256m
org.gradle.jvmargs=-Xmx2048m -XX:MaxMetaspaceSize=512m

# When configured, Gradle will run in incubating parallel mode.
# This option should only be used with decoupled projects. More details, visit
# http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects
# org.gradle.parallel=true

# AndroidX package structure to make it clearer which packages are bundled with the
# Android operating system, and which are packaged with your app's APK
# https://developer.android.com/topic/libraries/support-library/androidx-rn
android.useAndroidX=true

# Enable AAPT2 PNG crunching
android.enablePngCrunchInReleaseBuilds=true

# Use this property to specify which architecture you want to build.
# You can also override it from the CLI using
# ./gradlew <task> -PreactNativeArchitectures=x86_64
reactNativeArchitectures=armeabi-v7a,arm64-v8a,x86,x86_64

# Use this property to enable support to the new architecture.
# This will allow you to use TurboModules and the Fabric render in
# your application. You should enable this flag either if you want
# to write custom TurboModules/Fabric components OR use libraries that
# are providing them.
newArchEnabled=true

# Use this property to enable or disable the Hermes JS engine.
# If set to false, you will be using JSC instead.
hermesEnabled=true

# Enable GIF support in React Native images (~200 B increase)
expo.gif.enabled=true
# Enable webp support in React Native images (~85 KB increase)
expo.webp.enabled=true
# Enable animated webp support (~3.4 MB increase)
# Disabled by default because iOS doesn't support animated webp
expo.webp.animated=false

# Enable network inspector
EX_DEV_CLIENT_NETWORK_INSPECTOR=true

# Use legacy packaging to compress native libraries in the resulting APK.
expo.useLegacyPackaging=false

================
File: android/gradle/wrapper/gradle-wrapper.properties
================
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-8.10.2-all.zip
networkTimeout=10000
validateDistributionUrl=true
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists

================
File: android/gradlew
================
#!/bin/sh

#
# Copyright © 2015-2021 the original authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0
#

##############################################################################
#
#   Gradle start up script for POSIX generated by Gradle.
#
#   Important for running:
#
#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is
#       noncompliant, but you have some other compliant shell such as ksh or
#       bash, then to run this script, type that shell name before the whole
#       command line, like:
#
#           ksh Gradle
#
#       Busybox and similar reduced shells will NOT work, because this script
#       requires all of these POSIX shell features:
#         * functions;
#         * expansions «$var», «${var}», «${var:-default}», «${var+SET}»,
#           «${var#prefix}», «${var%suffix}», and «$( cmd )»;
#         * compound commands having a testable exit status, especially «case»;
#         * various built-in commands including «command», «set», and «ulimit».
#
#   Important for patching:
#
#   (2) This script targets any POSIX shell, so it avoids extensions provided
#       by Bash, Ksh, etc; in particular arrays are avoided.
#
#       The "traditional" practice of packing multiple parameters into a
#       space-separated string is a well documented source of bugs and security
#       problems, so this is (mostly) avoided, by progressively accumulating
#       options in "$@", and eventually passing that to Java.
#
#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,
#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;
#       see the in-line comments for details.
#
#       There are tweaks for specific operating systems such as AIX, CygWin,
#       Darwin, MinGW, and NonStop.
#
#   (3) This script is generated from the Groovy template
#       https://github.com/gradle/gradle/blob/HEAD/platforms/jvm/plugins-application/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt
#       within the Gradle project.
#
#       You can find Gradle at https://github.com/gradle/gradle/.
#
##############################################################################

# Attempt to set APP_HOME

# Resolve links: $0 may be a link
app_path=$0

# Need this for daisy-chained symlinks.
while
    APP_HOME=${app_path%"${app_path##*/}"}  # leaves a trailing /; empty if no leading path
    [ -h "$app_path" ]
do
    ls=$( ls -ld "$app_path" )
    link=${ls#*' -> '}
    case $link in             #(
      /*)   app_path=$link ;; #(
      *)    app_path=$APP_HOME$link ;;
    esac
done

# This is normally unused
# shellcheck disable=SC2034
APP_BASE_NAME=${0##*/}
# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)
APP_HOME=$( cd -P "${APP_HOME:-./}" > /dev/null && printf '%s
' "$PWD" ) || exit

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD=maximum

warn () {
    echo "$*"
} >&2

die () {
    echo
    echo "$*"
    echo
    exit 1
} >&2

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
nonstop=false
case "$( uname )" in                #(
  CYGWIN* )         cygwin=true  ;; #(
  Darwin* )         darwin=true  ;; #(
  MSYS* | MINGW* )  msys=true    ;; #(
  NONSTOP* )        nonstop=true ;;
esac

CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar


# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD=$JAVA_HOME/jre/sh/java
    else
        JAVACMD=$JAVA_HOME/bin/java
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD=java
    if ! command -v java >/dev/null 2>&1
    then
        die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
fi

# Increase the maximum file descriptors if we can.
if ! "$cygwin" && ! "$darwin" && ! "$nonstop" ; then
    case $MAX_FD in #(
      max*)
        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        MAX_FD=$( ulimit -H -n ) ||
            warn "Could not query maximum file descriptor limit"
    esac
    case $MAX_FD in  #(
      '' | soft) :;; #(
      *)
        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        ulimit -n "$MAX_FD" ||
            warn "Could not set maximum file descriptor limit to $MAX_FD"
    esac
fi

# Collect all arguments for the java command, stacking in reverse order:
#   * args from the command line
#   * the main class name
#   * -classpath
#   * -D...appname settings
#   * --module-path (only if needed)
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.

# For Cygwin or MSYS, switch paths to Windows format before running java
if "$cygwin" || "$msys" ; then
    APP_HOME=$( cygpath --path --mixed "$APP_HOME" )
    CLASSPATH=$( cygpath --path --mixed "$CLASSPATH" )

    JAVACMD=$( cygpath --unix "$JAVACMD" )

    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    for arg do
        if
            case $arg in                                #(
              -*)   false ;;                            # don't mess with options #(
              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath
                    [ -e "$t" ] ;;                      #(
              *)    false ;;
            esac
        then
            arg=$( cygpath --path --ignore --mixed "$arg" )
        fi
        # Roll the args list around exactly as many times as the number of
        # args, so each arg winds up back in the position where it started, but
        # possibly modified.
        #
        # NB: a `for` loop captures its iteration list before it begins, so
        # changing the positional parameters here affects neither the number of
        # iterations, nor the values presented in `arg`.
        shift                   # remove old arg
        set -- "$@" "$arg"      # push replacement arg
    done
fi


# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS='"-Xmx64m" "-Xms64m"'

# Collect all arguments for the java command:
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,
#     and any embedded shellness will be escaped.
#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be
#     treated as '${Hostname}' itself on the command line.

set -- \
        "-Dorg.gradle.appname=$APP_BASE_NAME" \
        -classpath "$CLASSPATH" \
        org.gradle.wrapper.GradleWrapperMain \
        "$@"

# Stop when "xargs" is not available.
if ! command -v xargs >/dev/null 2>&1
then
    die "xargs is not available"
fi

# Use "xargs" to parse quoted args.
#
# With -n1 it outputs one arg per line, with the quotes and backslashes removed.
#
# In Bash we could simply go:
#
#   readarray ARGS < <( xargs -n1 <<<"$var" ) &&
#   set -- "${ARGS[@]}" "$@"
#
# but POSIX shell has neither arrays nor command substitution, so instead we
# post-process each arg (as a line of input to sed) to backslash-escape any
# character that might be a shell metacharacter, then use eval to reverse
# that process (while maintaining the separation between arguments), and wrap
# the whole thing up as a single "set" statement.
#
# This will of course break if any of these variables contains a newline or
# an unmatched quote.
#

eval "set -- $(
        printf '%s\n' "$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS" |
        xargs -n1 |
        sed ' s~[^-[:alnum:]+,./:=@_]~\\&~g; ' |
        tr '\n' ' '
    )" '"$@"'

exec "$JAVACMD" "$@"

================
File: android/gradlew.bat
================
@rem
@rem Copyright 2015 the original author or authors.
@rem
@rem Licensed under the Apache License, Version 2.0 (the "License");
@rem you may not use this file except in compliance with the License.
@rem You may obtain a copy of the License at
@rem
@rem      https://www.apache.org/licenses/LICENSE-2.0
@rem
@rem Unless required by applicable law or agreed to in writing, software
@rem distributed under the License is distributed on an "AS IS" BASIS,
@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
@rem See the License for the specific language governing permissions and
@rem limitations under the License.
@rem
@rem SPDX-License-Identifier: Apache-2.0
@rem

@if "%DEBUG%"=="" @echo off
@rem ##########################################################################
@rem
@rem  Gradle startup script for Windows
@rem
@rem ##########################################################################

@rem Set local scope for the variables with windows NT shell
if "%OS%"=="Windows_NT" setlocal

set DIRNAME=%~dp0
if "%DIRNAME%"=="" set DIRNAME=.
@rem This is normally unused
set APP_BASE_NAME=%~n0
set APP_HOME=%DIRNAME%

@rem Resolve any "." and ".." in APP_HOME to make it shorter.
for %%i in ("%APP_HOME%") do set APP_HOME=%%~fi

@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
set DEFAULT_JVM_OPTS="-Xmx64m" "-Xms64m"

@rem Find java.exe
if defined JAVA_HOME goto findJavaFromJavaHome

set JAVA_EXE=java.exe
%JAVA_EXE% -version >NUL 2>&1
if %ERRORLEVEL% equ 0 goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH. 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:findJavaFromJavaHome
set JAVA_HOME=%JAVA_HOME:"=%
set JAVA_EXE=%JAVA_HOME%/bin/java.exe

if exist "%JAVA_EXE%" goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME% 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:execute
@rem Setup the command line

set CLASSPATH=%APP_HOME%\gradle\wrapper\gradle-wrapper.jar


@rem Execute Gradle
"%JAVA_EXE%" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% "-Dorg.gradle.appname=%APP_BASE_NAME%" -classpath "%CLASSPATH%" org.gradle.wrapper.GradleWrapperMain %*

:end
@rem End local scope for the variables with windows NT shell
if %ERRORLEVEL% equ 0 goto mainEnd

:fail
rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of
rem the _cmd.exe /c_ return code!
set EXIT_CODE=%ERRORLEVEL%
if %EXIT_CODE% equ 0 set EXIT_CODE=1
if not ""=="%GRADLE_EXIT_CONSOLE%" exit %EXIT_CODE%
exit /b %EXIT_CODE%

:mainEnd
if "%OS%"=="Windows_NT" endlocal

:omega

================
File: android/settings.gradle
================
pluginManagement {
    includeBuild(new File(["node", "--print", "require.resolve('@react-native/gradle-plugin/package.json')"].execute(null, rootDir).text.trim()).getParentFile().toString())
}
plugins { id("com.facebook.react.settings") }

extensions.configure(com.facebook.react.ReactSettingsExtension) { ex ->
  if (System.getenv('EXPO_USE_COMMUNITY_AUTOLINKING') == '1') {
    ex.autolinkLibrariesFromCommand()
  } else {
    def command = [
      'node',
      '--no-warnings',
      '--eval',
      'require(require.resolve(\'expo-modules-autolinking\', { paths: [require.resolve(\'expo/package.json\')] }))(process.argv.slice(1))',
      'react-native-config',
      '--json',
      '--platform',
      'android'
    ].toList()
    ex.autolinkLibrariesFromCommand(command)
  }
}

rootProject.name = 'StoryWriter'

dependencyResolutionManagement {
  versionCatalogs {
    reactAndroidLibs {
      from(files(new File(["node", "--print", "require.resolve('react-native/package.json')"].execute(null, rootDir).text.trim(), "../gradle/libs.versions.toml")))
    }
  }
}

apply from: new File(["node", "--print", "require.resolve('expo/package.json')"].execute(null, rootDir).text.trim(), "../scripts/autolinking.gradle");
useExpoModules()

include ':app'
includeBuild(new File(["node", "--print", "require.resolve('@react-native/gradle-plugin/package.json', { paths: [require.resolve('react-native/package.json')] })"].execute(null, rootDir).text.trim()).getParentFile())

================
File: app.config.js
================
require('dotenv').config();

export default ({ config }) => ({
  ...config, 
  expo: {
    name: "StoryWriter",
    slug: "storywriter",
    version: "1.0.0",
    sdkVersion: "52.0.0",
    orientation: "landscape",
    icon: "./assets/images/icon.png",
    scheme: "storywriter",
    userInterfaceStyle: "automatic",
    newArchEnabled: true,
    splash: {
      image: "./assets/images/splash.png",
      resizeMode: "contain",
      backgroundColor: "#ffffff"
    },
    ios: {
      supportsTablet: true,
      bundleIdentifier: "com.portfola.StoryWriter",
      infoPlist: {
        NSMicrophoneUsageDescription: "This app needs access to microphone for voice input",
        NSSpeechRecognitionUsageDescription: "This app needs access to speech recognition for voice commands",
        UIBackgroundModes: ["audio"],
        UISupportedInterfaceOrientations: [
          "UIInterfaceOrientationLandscapeLeft",
          "UIInterfaceOrientationLandscapeRight"
        ]
      }
    },
    android: {
      package: "com.portfola.StoryWriter",
      adaptiveIcon: {
        foregroundImage: "./assets/images/adaptive-icon.png",
        backgroundColor: "#ffffff"
      },
      orientation: "landscape"  // Changed from screenOrientation
    },
    plugins: [
      "expo-router",
      "expo-dev-client",
      [
        "@react-native-voice/voice",
        {
          microphonePermission: "Allow $(PRODUCT_NAME) to access the microphone",
          speechRecognitionPermission: "Allow $(PRODUCT_NAME) to securely recognize user speech",
        },
      ]
    ],
    extra: {
      HUGGING_FACE_API_KEY: process.env.HUGGING_FACE_API_KEY,
      AWS_ACCESS_KEY_ID: process.env.AWS_ACCESS_KEY_ID,
      AWS_SECRET_ACCESS_KEY: process.env.AWS_SECRET_ACCESS_KEY,
      AWS_REGION: process.env.AWS_REGION,
      eas: {
        projectId: "ddc93476-3b8d-4b46-8ffa-de979a17a116"
      }
    }
  }
});

================
File: app/_layout.tsx
================
// app/_layout.tsx
import { Stack } from 'expo-router';
import * as ScreenOrientation from 'expo-screen-orientation';
import React, { useEffect } from 'react';
import { Platform } from 'react-native';

export default function RootLayout() {
  useEffect(() => {
    if (Platform.OS !== 'web') {
      ScreenOrientation.lockAsync(
        ScreenOrientation.OrientationLock.LANDSCAPE_RIGHT
      );
    }
  }, []);

  return <Stack screenOptions={{ headerShown: false }} />;
}

================
File: app/+not-found.tsx
================
import React from 'react';
import { Link, Stack } from 'expo-router';
import { StyleSheet } from 'react-native';

import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';

export default function NotFoundScreen() {
  return (
    <>
      <Stack.Screen options={{ title: 'Oops!' }} />
      <ThemedView style={styles.container}>
        <ThemedText type="title">This screen doesn't exist.</ThemedText>
        <Link href="/" style={styles.link}>
          <ThemedText type="link">Go to home screen!</ThemedText>
        </Link>
      </ThemedView>
    </>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
    padding: 20,
  },
  link: {
    marginTop: 15,
    paddingVertical: 15,
  },
});

================
File: app/index.tsx
================
import React from 'react';
import { View, Text, TouchableOpacity, StyleSheet } from 'react-native';
import { Link } from 'expo-router';

export default function Index() {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>StoryWriter</Text>
      <Text style={styles.subtitle}>Create amazing stories with your voice!</Text>
      
      <View style={styles.buttonContainer}>
        <Link href="/story" asChild>
          <TouchableOpacity style={styles.button}>
            <Text style={styles.buttonText}>Start Writing</Text>
          </TouchableOpacity>
        </Link>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#f0f8ff',
    padding: 20,
  },
  title: {
    fontSize: 48,
    fontWeight: 'bold',
    color: '#3498db',
    marginBottom: 10,
  },
  subtitle: {
    fontSize: 24,
    color: '#666',
    marginBottom: 40,
  },
  buttonContainer: {
    alignItems: 'center',
  },
  button: {
    backgroundColor: '#3498db',
    paddingHorizontal: 40,
    paddingVertical: 15,
    borderRadius: 30,
    minWidth: 200,
    alignItems: 'center',
  },
  buttonText: {
    color: 'white',
    fontSize: 20,
    fontWeight: '600',
  },
});

================
File: app/story-original.tsx
================
import React, { useEffect } from 'react';
import { View, Text, TouchableOpacity, StyleSheet } from 'react-native';
import * as Speech from 'expo-speech'; // For text-to-speech (TTS)
import Voice, { SpeechResultsEvent } from '@react-native-voice/voice'; // For voice-to-text
import { router } from 'expo-router'; // For navigation
import HuggingFaceService from '@/services/huggingFaceService'; // Service for AI responses
import StoryDisplay from '@/components/StoryDisplay'; // Component to display the generated story
import VoiceWave from '@/components/VoiceWave'; // Visual feedback for voice input/output
import useConversationStore from '@/src/stores/conversationStore'; // Global state management

/**
 * StoryScreen: The main screen for the storytelling process.
 * It handles the user's interaction via voice, processes their input,
 * and generates a story using AI.
 */
export default function StoryScreen() {
  // Extract states from the conversation store
  const phase = useConversationStore(state => state.phase); // Current app phase
  const currentQuestion = useConversationStore(state => state.currentQuestion); // Current question asked by AI
  const conversationHistory = useConversationStore(state => state.conversationHistory); // Full conversation log
  const isListening = useConversationStore(state => state.isListening); // Whether the app is recording voice
  const isSpeaking = useConversationStore(state => state.isSpeaking); // Whether the app is speaking (TTS)
  const speechRate = useConversationStore(state => state.speechRate); // Speed of TTS output
  const speechVolume = useConversationStore(state => state.speechVolume); // Volume of TTS output
  const currentPageIndex = useConversationStore(state => state.currentPageIndex); // Current story page index
  const storyPages = useConversationStore(state => state.storyPages); // List of story pages

  // Extract actions from the conversation store
  const startConversation = useConversationStore(state => state.startConversation); // Begin a new conversation
  const addUserResponse = useConversationStore(state => state.addUserResponse); // Add a user's input to the conversation
  const setQuestion = useConversationStore(state => state.setQuestion); // Set the next question
  const setSpeechState = useConversationStore(state => state.setSpeechState); // Update TTS/voice state
  const setPhase = useConversationStore(state => state.setPhase); // Change the app's current phase
  const setError = useConversationStore(state => state.setError); // Set an error message
  const setStoryPages = useConversationStore(state => state.setStoryPages); // Update story pages
  const resetConversation = useConversationStore(state => state.resetConversation); // Reset the conversation

  /**
   * Initialize the conversation when the app first loads.
   * Starts in the 'INITIAL' phase and transitions to asking the first question.
   */
  useEffect(() => {
    const initialize = async () => {
      if (phase === 'INITIAL') {
        await startConversation();
      }
    };
    initialize();
  }, [phase, startConversation]);

  /**
   * Handle results from voice recognition.
   * Processes the text captured by the microphone.
   */
  const handleSpeechResults = (e: SpeechResultsEvent) => {
    if (e.value && e.value.length > 0) {
      const text = e.value[0]; // Take the first recognized result
      if (text) {
        if (isSpeaking) {
          handleInterruption(text); // Handle interruptions during speech output
        } else {
          handleAnswer(text); // Handle user's response
        }
      }
    }
  };

  /**
   * Speak a given text aloud using TTS.
   * Updates the speaking state to prevent conflicts during output.
   */
  const speak = async (text: string) => {
    try {
      if (isSpeaking) {
        await Speech.stop(); // Stop any ongoing speech
      }
      setSpeechState({ isSpeaking: true }); // Indicate speaking has started

      await Speech.speak(text, {
        rate: speechRate,
        volume: speechVolume,
        onDone: () => setSpeechState({ isSpeaking: false }),
        onError: () => {
          setSpeechState({ isSpeaking: false });
          setError('Failed to speak');
        },
      });
    } catch (error) {
      console.error('Error in speak function:', error);
      setSpeechState({ isSpeaking: false });
      setError('Failed to speak');
    }
  };

  /**
   * Initialize voice recognition and prepare listeners.
   * Cleans up resources when the component unmounts.
   */
  useEffect(() => {
    if (phase !== 'INITIAL') {
      const initVoice = async () => {
        try {
          // Set up voice recognition event handlers
          Voice.onSpeechStart = () => setSpeechState({ isListening: true });
          Voice.onSpeechEnd = () => setSpeechState({ isListening: false });
          Voice.onSpeechError = (error) => {
            console.error('Speech error:', error);
            setSpeechState({ isListening: false });
            setError(`Speech recognition error: ${error.message}`);
          };
          Voice.onSpeechResults = handleSpeechResults;

          // Speak the current question aloud
          if (currentQuestion) {
            await speak(currentQuestion);
          }
        } catch (error) {
          console.error('Error initializing voice:', error);
          setError('Failed to initialize voice recognition');
        }
      };
      initVoice();
    }

    // Cleanup function to release resources
    return () => {
      const cleanup = async () => {
        try {
          await Voice.destroy();
          await Speech.stop();
          Voice.removeAllListeners();
        } catch (error) {
          console.error('Error during cleanup:', error);
        }
      };
      cleanup();
    };
  }, [phase, currentQuestion, setSpeechState, setError]);

  /**
   * Generate the next question or story segment.
   * Uses AI to analyze the current conversation and decide the next step.
   */
  const generateNextQuestion = async () => {
    if (phase !== 'INTERVIEWING' || isSpeaking) {
      console.log('Blocked question generation due to current state.');
      return;
    }
    try {
      setPhase('PROCESSING'); // Transition to processing phase

      // Build a prompt for the AI
      const prompt = `Based on our conversation so far, ask the next question...`;
      const response = await HuggingFaceService.generateResponse(prompt);

      if (response.includes('INTERVIEW_COMPLETE')) {
        const summary = response.split('INTERVIEW_COMPLETE')[1].trim();
        await generateAndDisplayStory(summary); // Transition to story generation
      } else {
        setQuestion(response.trim());
        await speak(response.trim());
      }
    } catch (error) {
      console.error('Error generating question:', error);
      setError('Failed to generate question.');
    }
  };

  return (
    <View style={styles.container}>
      <TouchableOpacity style={styles.backButton} onPress={() => router.push('/')}>
        <Text style={styles.backButtonText}>← Back</Text>
      </TouchableOpacity>

      <View style={styles.contentContainer}>
        {phase === 'DISPLAYING_STORY' ? (
          <StoryDisplay storyPages={storyPages} currentPageIndex={currentPageIndex} />
        ) : (
          <>
            <Text style={styles.currentQuestion}>{currentQuestion}</Text>
            <VoiceWave isListening={isListening} isSpeaking={isSpeaking} />
            {phase === 'PROCESSING' && (
              <Text style={styles.processingText}>Processing your response...</Text>
            )}
          </>
        )}
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: '#f0f8ff' },
  backButton: { position: 'absolute', top: 20, left: 20, padding: 10, backgroundColor: '#3498db', borderRadius: 8 },
  backButtonText: { color: 'white', fontSize: 16, fontWeight: '600' },
  contentContainer: { flex: 1, justifyContent: 'center', alignItems: 'center', padding: 20 },
  currentQuestion: { fontSize: 24, marginBottom: 30, textAlign: 'center' },
  processingText: { fontSize: 16, fontStyle: 'italic', color: '#666', marginTop: 10 },
});

================
File: app/story.tsx
================
import React, { useState, useEffect } from 'react';
import { View, Text, TouchableOpacity, StyleSheet, ScrollView, Image, ActivityIndicator } from 'react-native';
import * as Speech from 'expo-speech';
import TranscribeService from '@/services/transcribe';
import HuggingFaceService from '@/services/huggingFaceService';
import { usePolly } from '@/hooks/usePolly';

declare global {
  interface Window {
    webkitSpeechRecognition: any;
  }
}

interface StorySection {
  text: string;
  imageUrl: string | null;
}

/**
 * StoryScreen: The main component responsible for the story creation process.
 * It interacts with the user via voice commands to gather input for story generation.
 * 
 * Features:
 * - Prompts the user with questions using text-to-speech.
 * - Records user's voice responses using s peech recognition.
 * - Manages conversation state and user responses.
 * - Generates a story based on collected responses using an AI service.
 * 
 * State:
 * - question: The current question being asked to the user.
 * - responses: List of user responses gathered during the session.
 * - isListening: Boolean indicating if the app is actively listening for voice input.
 * - conversationComplete: Boolean indicating if the user has finished providing input.
 * - generatedStory: The final story generated from the user's responses.
 * 
 * Usage:
 * - Tap the button to start speaking and provide input.
 * - The app will guide the user with questions and generate a story from the responses.
 */

export default function StoryScreen() {
  const [question, setQuestion] = useState('What kind of story would you like?');
  const [responses, setResponses] = useState<string[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [conversationComplete, setConversationComplete] = useState(false);
  const [storyContent, setStoryContent] = useState<StorySection[]>([]);
  const [generatedStory, setGeneratedStory] = useState<string | null>(null);
  const [isGenerating, setIsGenerating] = useState(false);
  const { speak, stop } = usePolly();
  

  const startListening = async () => {
    try {
      setIsListening(true);

      // Stop any ongoing speech before starting to listen
      stop();
      
      await TranscribeService.startTranscription((transcript) => {
        // Check if they want to finish
        const isDone = ['i\'m done', 'that\'s all', 'finish'].some(
          phrase => transcript.toLowerCase().includes(phrase)
        );

        if (isDone) {
          TranscribeService.stopTranscription();
          setConversationComplete(true);
          speak("Okay! I will now create your story.");
        } else {
          setResponses(prev => [...prev, transcript]);
        }
      });
    } catch (error) {
      console.error('Transcription error:', error);
      alert('Failed to start listening. Please try again.');
    } finally {
      setIsListening(false);
    };

  };

    
  useEffect(() => {
    if (!conversationComplete) {
      const questionText = responses.length > 0 
        ? "OK, and what else?" 
        : "What kind of story shall we create together?";
      stop();
      setTimeout(() => speak(questionText), 3000);
      setQuestion(questionText);
    }
  }, [responses, conversationComplete]);

  useEffect(() => {
    return () => {
      stop(); // Cleanup when component unmounts
    };
  }, [stop]);


  const generateStory = async () => {
    try {
      const fullPrompt = `Create a children's story based on the following details:\n\n${responses.join(' ')}\n\nMake it engaging and appropriate for a 5-year-old.`;
      const response = await HuggingFaceService.generateResponse(fullPrompt);
      setGeneratedStory(response);
    } catch (error) {
      console.error("Error:", error);
      alert('Failed to generate story. Please try again.');
    }
  };


  const generateImage = async (prompt: string): Promise<string | null> => {
    try {
      // Assuming HuggingFaceService has an imageGeneration method
      const imageUrl = await HuggingFaceService.generateImage(
        `child-friendly, safe, cartoon style illustration of ${prompt}`
      );
      console.log(imageUrl);
      return imageUrl;
    } catch (error) {
      console.error('Image generation error:', error);
      return null;
    }
  };

  const splitStoryIntoSections = (story: string): string[] => {
    // Split story into sections based on paragraphs or sentences
    return story
      .split(/(?<=[.!?])\s+/)
      .reduce((acc: string[], sentence: string, i: number) => {
        if (i % 2 === 0) {
          acc.push(sentence);
        } else {
          acc[acc.length - 1] += ' ' + sentence;
        }
        return acc;
      }, []);
  };

  const generateStoryWithImages = async () => {
    stop();
    setIsGenerating(true);
    try {
      // Generate the story text
      const fullPrompt = `Create a children's story based on the following details:\n\n${responses.join(' ')}\n\nMake it engaging and appropriate for a 5-year-old. Keep paragraphs short.`;
      const storyText = await HuggingFaceService.generateResponse(fullPrompt);
      
      // Split the story into sections
      const sections = splitStoryIntoSections(storyText);
      
      // Generate images for each section
      const storyWithImages = await Promise.all(
        sections.map(async (text): Promise<StorySection> => {
          const imageUrl = await generateImage(text);
          console.log('imageUrl. story.tsx:Line 144', imageUrl);
          return { text, imageUrl };
        })
      );
      
      setStoryContent(storyWithImages);
    } catch (error) {
      console.error("Error:", error);
      alert('Failed to generate story. Please try again.');
    } finally {
      setIsGenerating(false);
    }
  };

  const stopListening = async () => {
    await TranscribeService.stopTranscription();
    setIsListening(false);
    setConversationComplete(true);
    stop();
    speak("Okay! I will now create your story.");
  };

  return (
    <View style={styles.container}>
      {!generatedStory ? (
        <>
          <Text style={styles.questionText}>{question}</Text>

          {!conversationComplete && (
          <View style={styles.buttonContainer}>
            <TouchableOpacity 
              style={styles.button} 
              onPress={startListening} 
              disabled={isListening}
            >
              <Text style={styles.buttonText}>
                {isListening ? 'Listening...' : 'Tap to Speak'}
              </Text>
            </TouchableOpacity>

            {isListening && (
              <TouchableOpacity 
                style={[styles.button, styles.stopButton]} 
                onPress={stopListening}
              >
                <Text style={styles.buttonText}>Stop Listening</Text>
              </TouchableOpacity>
            )}
          </View>
        )}

          {responses.length > 0 && (
            <View style={styles.responseContainer}>
              <Text style={styles.responseLabel}>Your story so far:</Text>
              {responses.map((res, index) => (
                <Text key={index} style={styles.responseText}>
                  {index + 1}. {res}
                </Text>
              ))}
            </View>
          )}

          {(conversationComplete || responses.length > 0) && (
            <TouchableOpacity 
              style={styles.finishButton} 
              onPress={generateStoryWithImages}
              disabled={isGenerating}
            >
                 <Text style={styles.buttonText}>
                  {isGenerating ? 'Generating...' : 'Generate Story with Images'}
                </Text>
            </TouchableOpacity>
          )}
        </>
      ) : (
        <ScrollView style={styles.storyContainer}>
          <Text style={styles.storyTitle}>Your Story:</Text>
          <Text style={styles.storyText}>{generatedStory}</Text>
  
        {storyContent.map((section, index) => (
          <View key={index} style={styles.sectionContainer}>
            <Text style={styles.storyText}>{section.text}</Text>
            {section.imageUrl && (
              <Image
                source={{ uri: section.imageUrl }}
                style={styles.storyImage}
                resizeMode="contain"
              />
            )}
          </View>
        ))}
      </ScrollView>
      )}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#f0f8ff',
    padding: 20,
  },
  questionText: {
    fontSize: 20,
    fontWeight: 'bold',
    textAlign: 'center',
    marginBottom: 20,
    color: '#2c3e50',
  },
  button: {
    backgroundColor: '#3498db',
    padding: 15,
    borderRadius: 10,
  },
  finishButton: {
    backgroundColor: '#2ecc71',
    padding: 15,
    borderRadius: 10,
    marginTop: 20,
  },
  buttonText: {
    color: 'white',
    fontSize: 18,
    fontWeight: 'bold',
  },
  responseContainer: {
    marginTop: 20,
    paddingHorizontal: 20,
  },
  responseLabel: {
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 10,
    color: '#2c3e50',
  },
  responseText: {
    fontSize: 16,
    color: '#34495e',
    marginBottom: 5,
  },
  storyContainer: {
    flex: 1,
    padding: 20,
    backgroundColor: '#fff',
  },
  storyTitle: {
    fontSize: 22,
    fontWeight: 'bold',
    textAlign: 'center',
    marginBottom: 15,
  },
  storyText: {
    fontSize: 18,
    lineHeight: 26,
    color: '#2c3e50',
  },
  storyImage: {
    width: '100%', // Set this to full width
    height: 200,   // Add a fixed height
    marginVertical: 10,
  },
  sectionContainer: {
    marginBottom: 20,
  },
  buttonContainer: {
    marginBottom: 20,
  },
  stopButton: {
    marginTop: 20,
  },
});

================
File: babel.config.js
================
module.exports = function(api) {
  api.cache(true);
  return {
    presets: ['babel-preset-expo'],
    plugins: [
      [
        'module-resolver',
        {
          root: ['.'],
          alias: {
            '@': '.',
            "@env": "./.env", // ✅ Explicitly add @env alias
          },
        },
      ],
      "module:react-native-dotenv",
    ],
  };
}

================
File: components/__tests__/__snapshots__/ThemedText-test.tsx.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`renders correctly 1`] = `
<Text
  style={
    [
      {
        "color": "#11181C",
      },
      {
        "fontSize": 16,
        "lineHeight": 24,
      },
      undefined,
      undefined,
      undefined,
      undefined,
      undefined,
    ]
  }
>
  Snapshot test!
</Text>
`;

================
File: components/__tests__/ThemedText-test.tsx
================
import * as React from 'react';
import renderer from 'react-test-renderer';

import { ThemedText } from '../ThemedText';

it(`renders correctly`, () => {
  const tree = renderer.create(<ThemedText>Snapshot test!</ThemedText>).toJSON();

  expect(tree).toMatchSnapshot();
});

================
File: components/Collapsible.tsx
================
import Ionicons from '@expo/vector-icons/Ionicons';
import { PropsWithChildren, useState } from 'react';
import { StyleSheet, TouchableOpacity, useColorScheme } from 'react-native';

import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';
import { Colors } from '@/constants/Colors';

export function Collapsible({ children, title }: PropsWithChildren & { title: string }) {
  const [isOpen, setIsOpen] = useState(false);
  const theme = useColorScheme() ?? 'light';

  return (
    <ThemedView>
      <TouchableOpacity
        style={styles.heading}
        onPress={() => setIsOpen((value) => !value)}
        activeOpacity={0.8}>
        <Ionicons
          name={isOpen ? 'chevron-down' : 'chevron-forward-outline'}
          size={18}
          color={theme === 'light' ? Colors.light.icon : Colors.dark.icon}
        />
        <ThemedText type="defaultSemiBold">{title}</ThemedText>
      </TouchableOpacity>
      {isOpen && <ThemedView style={styles.content}>{children}</ThemedView>}
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  heading: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 6,
  },
  content: {
    marginTop: 6,
    marginLeft: 24,
  },
});

================
File: components/ExternalLink.tsx
================
import { Link } from 'expo-router';
import { openBrowserAsync } from 'expo-web-browser';
import { type ComponentProps } from 'react';
import { Platform } from 'react-native';

type Props = Omit<ComponentProps<typeof Link>, 'href'> & { href: string };

export function ExternalLink({ href, ...rest }: Props) {
  return (
    <Link
      target="_blank"
      {...rest}
      href={href}
      onPress={async (event) => {
        if (Platform.OS !== 'web') {
          // Prevent the default behavior of linking to the default browser on native.
          event.preventDefault();
          // Open the link in an in-app browser.
          await openBrowserAsync(href);
        }
      }}
    />
  );
}

================
File: components/HelloWave.tsx
================
import { StyleSheet } from 'react-native';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
  withRepeat,
  withSequence,
} from 'react-native-reanimated';

import { ThemedText } from '@/components/ThemedText';

export function HelloWave() {
  const rotationAnimation = useSharedValue(0);

  rotationAnimation.value = withRepeat(
    withSequence(withTiming(25, { duration: 150 }), withTiming(0, { duration: 150 })),
    4 // Run the animation 4 times
  );

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ rotate: `${rotationAnimation.value}deg` }],
  }));

  return (
    <Animated.View style={animatedStyle}>
      <ThemedText style={styles.text}>👋</ThemedText>
    </Animated.View>
  );
}

const styles = StyleSheet.create({
  text: {
    fontSize: 28,
    lineHeight: 32,
    marginTop: -6,
  },
});

================
File: components/navigation/TabBarIcon.tsx
================
// You can explore the built-in icon families and icons on the web at https://icons.expo.fyi/

import Ionicons from '@expo/vector-icons/Ionicons';
import * as React from 'react';

import { type IconProps } from '@expo/vector-icons/build/createIconSet';
import { type ComponentProps } from 'react';

export function TabBarIcon({ style, ...rest }: IconProps<ComponentProps<typeof Ionicons>['name']>) {
  return <Ionicons size={28} style={[{ marginBottom: -3 }, style]} {...rest} />;
}

================
File: components/ParallaxScrollView.tsx
================
import type { PropsWithChildren, ReactElement } from 'react';
import { StyleSheet, useColorScheme } from 'react-native';
import Animated, {
  interpolate,
  useAnimatedRef,
  useAnimatedStyle,
  useScrollViewOffset,
} from 'react-native-reanimated';

import { ThemedView } from '@/components/ThemedView';

const HEADER_HEIGHT = 250;

type Props = PropsWithChildren<{
  headerImage: ReactElement;
  headerBackgroundColor: { dark: string; light: string };
}>;

export default function ParallaxScrollView({
  children,
  headerImage,
  headerBackgroundColor,
}: Props) {
  const colorScheme = useColorScheme() ?? 'light';
  const scrollRef = useAnimatedRef<Animated.ScrollView>();
  const scrollOffset = useScrollViewOffset(scrollRef);

  const headerAnimatedStyle = useAnimatedStyle(() => {
    return {
      transform: [
        {
          translateY: interpolate(
            scrollOffset.value,
            [-HEADER_HEIGHT, 0, HEADER_HEIGHT],
            [-HEADER_HEIGHT / 2, 0, HEADER_HEIGHT * 0.75]
          ),
        },
        {
          scale: interpolate(scrollOffset.value, [-HEADER_HEIGHT, 0, HEADER_HEIGHT], [2, 1, 1]),
        },
      ],
    };
  });

  return (
    <ThemedView style={styles.container}>
      <Animated.ScrollView ref={scrollRef} scrollEventThrottle={16}>
        <Animated.View
          style={[
            styles.header,
            { backgroundColor: headerBackgroundColor[colorScheme] },
            headerAnimatedStyle,
          ]}>
          {headerImage}
        </Animated.View>
        <ThemedView style={styles.content}>{children}</ThemedView>
      </Animated.ScrollView>
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
  header: {
    height: 250,
    overflow: 'hidden',
  },
  content: {
    flex: 1,
    padding: 32,
    gap: 16,
    overflow: 'hidden',
  },
});

================
File: components/QuestionArea.tsx
================
import React, { useState } from 'react';
import { View, Text, TextInput, Button, StyleSheet } from 'react-native';

interface QuestionAreaProps {
  question: string;
  onAnswer: (answer: string) => void;
  onVoiceInput: () => void;
  isListening: boolean;
}

const QuestionArea: React.FC<QuestionAreaProps> = ({ question, onAnswer, onVoiceInput, isListening }) => {
  const [answer, setAnswer] = useState('');

  const handleSubmit = () => {
    onAnswer(answer);
    setAnswer('');
  };

  return (
    <View style={styles.container}>
      <Text style={styles.question}>{question}</Text>
      <TextInput
        style={styles.input}
        value={answer}
        onChangeText={setAnswer}
        placeholder="Type your answer here"
      />
      <Button title="Submit" onPress={handleSubmit} />
      <Button 
        title={isListening ? "Stop Listening" : "Voice Input"} 
        onPress={onVoiceInput} 
      />
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    margin: 20,
  },
  question: {
    fontSize: 18,
    marginBottom: 10,
  },
  input: {
    borderWidth: 1,
    borderColor: '#ddd',
    padding: 10,
    marginBottom: 10,
  },
});

export default QuestionArea;

================
File: components/screens/WelcomeScreen.tsx
================
// components/WelcomeScreen.tsx
import React from 'react';
import { View, Text, TouchableOpacity, StyleSheet } from 'react-native';
import * as Speech from 'expo-speech';

interface WelcomeScreenProps {
  onNewStory: () => void;
  onOpenLibrary: () => void;
}

export default function WelcomeScreen({ onNewStory, onOpenLibrary }: WelcomeScreenProps) {
  React.useEffect(() => {
    Speech.speak('Welcome! Would you like to create a new story or open a previous one?');
  }, []);

  return (
    <View style={styles.container}>
      <Text style={styles.title}>Story Writer</Text>
      <View style={styles.buttonContainer}>
        <TouchableOpacity 
          style={[styles.button, styles.createButton]} 
          onPress={onNewStory}
        >
          <Text style={styles.buttonText}>Create New Story</Text>
        </TouchableOpacity>
        <TouchableOpacity 
          style={[styles.button, styles.libraryButton]} 
          onPress={onOpenLibrary}
        >
          <Text style={styles.buttonText}>Open Previous Story</Text>
        </TouchableOpacity>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  title: {
    fontSize: 32,
    fontWeight: 'bold',
    marginBottom: 40,
    color: '#FF69B4',
  },
  buttonContainer: {
    width: '100%',
    maxWidth: 300,
    gap: 20,
  },
  button: {
    padding: 20,
    borderRadius: 15,
    alignItems: 'center',
  },
  createButton: {
    backgroundColor: '#3498db',
  },
  libraryButton: {
    backgroundColor: '#2ecc71',
  },
  buttonText: {
    color: 'white',
    fontSize: 18,
    fontWeight: '600',
  },
});

================
File: components/SpeechControls.tsx
================
import React from 'react';
import { View, Text, StyleSheet } from 'react-native';
import Slider from '@react-native-community/slider';

interface SpeechControlsProps {
  speechRate: number;
  onSpeechRateChange: (rate: number) => void;
  speechVolume: number;
  onSpeechVolumeChange: (volume: number) => void;
}

const SpeechControls: React.FC<SpeechControlsProps> = ({
  speechRate,
  onSpeechRateChange,
  speechVolume,
  onSpeechVolumeChange
}) => {
  return (
    <View style={styles.container}>
      <Text style={styles.label}>Speech Rate:</Text>
      <Slider
        style={styles.slider}
        minimumValue={0.5}
        maximumValue={2}
        value={speechRate}
        onValueChange={onSpeechRateChange}
        step={0.1}
      />
      <Text style={styles.value}>{speechRate.toFixed(1)}x</Text>

      <Text style={styles.label}>Speech Volume:</Text>
      <Slider
        style={styles.slider}
        minimumValue={0}
        maximumValue={1}
        value={speechVolume}
        onValueChange={onSpeechVolumeChange}
        step={0.1}
      />
      <Text style={styles.value}>{(speechVolume * 100).toFixed(0)}%</Text>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    padding: 20,
    backgroundColor: '#f0f0f0',
    borderRadius: 10,
    marginBottom: 20,
  },
  label: {
    fontSize: 16,
    marginBottom: 5,
  },
  slider: {
    width: '100%',
    height: 40,
  },
  value: {
    fontSize: 14,
    textAlign: 'right',
    marginBottom: 10,
  },
});

export default SpeechControls;

================
File: components/StoryDisplay.tsx
================
import React from 'react';
import { View, Text, Image, ScrollView, Button, StyleSheet } from 'react-native';

interface StoryPage {
  textContent: string;
  imageUrl: string;
}

interface StoryDisplayProps {
  storyPages: StoryPage[];
  currentPageIndex: number;
  onPageChange: (index: number) => void;
}

const StoryDisplay: React.FC<StoryDisplayProps> = ({ storyPages, currentPageIndex, onPageChange }) => {
  return (
    <ScrollView style={styles.container}>
      <Text style={styles.title}>{`Page ${currentPageIndex + 1} of ${storyPages.length}`}</Text>
      <View style={styles.pageContent}>
        <Image 
          source={{ uri: storyPages[currentPageIndex]?.imageUrl }} 
          style={styles.image} 
        />
        <Text style={styles.text}>{storyPages[currentPageIndex]?.textContent}</Text>
      </View>
      <View style={styles.navigation}>
        <Button 
          title="Previous" 
          onPress={() => onPageChange(currentPageIndex - 1)}
          disabled={currentPageIndex === 0}
        />
        <Button 
          title="Next" 
          onPress={() => onPageChange(currentPageIndex + 1)}
          disabled={currentPageIndex === storyPages.length - 1}
        />
      </View>
    </ScrollView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 20,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 20,
  },
  pageContent: {
    marginBottom: 20,
  },
  image: {
    width: '100%',
    height: 200,
    resizeMode: 'cover',
    marginBottom: 10,
  },
  text: {
    fontSize: 16,
    lineHeight: 24,
  },
  navigation: {
    flexDirection: 'row',
    justifyContent: 'space-between',
  },
});

export default StoryDisplay;

================
File: components/StoryManagement.tsx
================
import React, { useState } from 'react';
import { View, Text, Button, FlatList, TouchableOpacity, StyleSheet, Modal } from 'react-native';
import { StoryPage } from '../src/utils/storyGenerator'; // Import this

interface Story {
  title: string;
  content: StoryPage[];
  elements: { [key: string]: string };
}

interface StoryManagementProps {
  onSave: () => void;
  onLoad: (index: number) => void;
  savedStories: Story[];
  onBack: () => void;
}

const StoryManagement: React.FC<StoryManagementProps> = ({ onSave, onLoad, savedStories }) => {
  const [modalVisible, setModalVisible] = useState(false);

  const handleSave = () => {
    onSave();
    // You might want to show a confirmation message here
  };

  const handleLoad = (index: number) => {
    onLoad(index);
    setModalVisible(false);
  };

  return (
    <View style={styles.container}>
      <Button title="Save Story" onPress={handleSave} />
      <Button title="Load Story" onPress={() => setModalVisible(true)} />

      <Modal
        animationType="slide"
        transparent={true}
        visible={modalVisible}
        onRequestClose={() => setModalVisible(false)}
      >
        <View style={styles.centeredView}>
          <View style={styles.modalView}>
            <Text style={styles.modalTitle}>Saved Stories</Text>
            {savedStories.length > 0 ? (
              <FlatList
                data={savedStories}
                keyExtractor={(item, index) => index.toString()}
                renderItem={({ item, index }) => (
                  <TouchableOpacity
                    style={styles.storyItem}
                    onPress={() => handleLoad(index)}
                  >
                    <Text>{item.title}</Text>
                  </TouchableOpacity>
                )}
              />
            ) : (
              <Text>No saved stories</Text>
            )}
            <Button title="Close" onPress={() => setModalVisible(false)} />
          </View>
        </View>
      </Modal>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    marginBottom: 20,
  },
  centeredView: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: 'rgba(0, 0, 0, 0.5)',
  },
  modalView: {
    margin: 20,
    backgroundColor: 'white',
    borderRadius: 20,
    padding: 35,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2
    },
    shadowOpacity: 0.25,
    shadowRadius: 4,
    elevation: 5,
    width: '80%',
    maxHeight: '80%',
  },
  modalTitle: {
    fontSize: 20,
    fontWeight: 'bold',
    marginBottom: 15,
  },
  storyItem: {
    padding: 10,
    borderBottomWidth: 1,
    borderBottomColor: '#ccc',
    width: '100%',
  },
});

export default StoryManagement;

================
File: components/ThemedText.tsx
================
import { Text, type TextProps, StyleSheet } from 'react-native';

import { useThemeColor } from '@/hooks/useThemeColor';

export type ThemedTextProps = TextProps & {
  lightColor?: string;
  darkColor?: string;
  type?: 'default' | 'title' | 'defaultSemiBold' | 'subtitle' | 'link';
};

export function ThemedText({
  style,
  lightColor,
  darkColor,
  type = 'default',
  ...rest
}: ThemedTextProps) {
  const color = useThemeColor({ light: lightColor, dark: darkColor }, 'text');

  return (
    <Text
      style={[
        { color },
        type === 'default' ? styles.default : undefined,
        type === 'title' ? styles.title : undefined,
        type === 'defaultSemiBold' ? styles.defaultSemiBold : undefined,
        type === 'subtitle' ? styles.subtitle : undefined,
        type === 'link' ? styles.link : undefined,
        style,
      ]}
      {...rest}
    />
  );
}

const styles = StyleSheet.create({
  default: {
    fontSize: 16,
    lineHeight: 24,
  },
  defaultSemiBold: {
    fontSize: 16,
    lineHeight: 24,
    fontWeight: '600',
  },
  title: {
    fontSize: 32,
    fontWeight: 'bold',
    lineHeight: 32,
  },
  subtitle: {
    fontSize: 20,
    fontWeight: 'bold',
  },
  link: {
    lineHeight: 30,
    fontSize: 16,
    color: '#0a7ea4',
  },
});

================
File: components/ThemedView.tsx
================
import { View, type ViewProps } from 'react-native';

import { useThemeColor } from '@/hooks/useThemeColor';

export type ThemedViewProps = ViewProps & {
  lightColor?: string;
  darkColor?: string;
};

export function ThemedView({ style, lightColor, darkColor, ...otherProps }: ThemedViewProps) {
  const backgroundColor = useThemeColor({ light: lightColor, dark: darkColor }, 'background');

  return <View style={[{ backgroundColor }, style]} {...otherProps} />;
}

================
File: components/VoiceWave.tsx
================
import React, { useState, useEffect } from 'react';
import { View, StyleSheet, Animated } from 'react-native';

// Define the props interface for type safety
interface VoiceWaveProps {
  isListening: boolean;
  isSpeaking: boolean;
  // We could add customization props here later, like:
  // barCount?: number;
  // activeColor?: string;
  // inactiveColor?: string;
}

const VoiceWave: React.FC<VoiceWaveProps> = ({ isListening, isSpeaking }) => {
  // Animation state is kept local because it's UI-specific and temporary
  const [waveAmplitudes] = useState(
    Array(10).fill(0).map(() => new Animated.Value(10))
  );

  useEffect(() => {
    let animationFrameId: number;

    const animate = () => {
      if (isListening || isSpeaking) {
        // Animate each bar to a random height when active
        waveAmplitudes.forEach(amplitude => {
          Animated.timing(amplitude, {
            toValue: Math.random() * 40 + 10,
            duration: 100,
            useNativeDriver: false,
          }).start();
        });
      } else {
        // Reset bars to default height when inactive
        waveAmplitudes.forEach(amplitude => {
          Animated.timing(amplitude, {
            toValue: 10,
            duration: 100,
            useNativeDriver: false,
          }).start();
        });
      }
      animationFrameId = requestAnimationFrame(animate);
    };

    // Start the animation loop
    animate();

    // Cleanup function to prevent memory leaks
    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [isListening, isSpeaking, waveAmplitudes]);

  return (
    <View style={styles.waveContainer}>
      {waveAmplitudes.map((amplitude, index) => (
        <Animated.View
          key={index}
          style={[
            styles.bar,
            {
              height: amplitude,
              backgroundColor: isListening ? '#ff6b6b' : (isSpeaking ? '#4ecdc4' : '#dddddd')
            }
          ]}
        />
      ))}
    </View>
  );
};

const styles = StyleSheet.create({
  waveContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    height: 60,
    gap: 4,
  },
  bar: {
    width: 4,
    borderRadius: 2,
  }
});

export default VoiceWave;

================
File: constants/Colors.ts
================
/**
 * Below are the colors that are used in the app. The colors are defined in the light and dark mode.
 * There are many other ways to style your app. For example, [Nativewind](https://www.nativewind.dev/), [Tamagui](https://tamagui.dev/), [unistyles](https://reactnativeunistyles.vercel.app), etc.
 */

const tintColorLight = '#0a7ea4';
const tintColorDark = '#fff';

export const Colors = {
  light: {
    text: '#11181C',
    background: '#fff',
    tint: tintColorLight,
    icon: '#687076',
    tabIconDefault: '#687076',
    tabIconSelected: tintColorLight,
  },
  dark: {
    text: '#ECEDEE',
    background: '#151718',
    tint: tintColorDark,
    icon: '#9BA1A6',
    tabIconDefault: '#9BA1A6',
    tabIconSelected: tintColorDark,
  },
};

================
File: eas.json
================
{
  "cli": {
    "version": ">= 14.1.0",
    "appVersionSource": "remote"
  },
  "build": {
    "development": {
      "developmentClient": true,
      "distribution": "internal"
    },
    "preview": {
      "distribution": "internal"
    },
    "production": {
      "autoIncrement": true
    }
  },
  "submit": {
    "production": {}
  }
}

================
File: hooks/useColorScheme.ts
================
export { useColorScheme } from 'react-native';

================
File: hooks/useColorScheme.web.ts
================
// NOTE: The default React Native styling doesn't support server rendering.
// Server rendered styles should not change between the first render of the HTML
// and the first render on the client. Typically, web developers will use CSS media queries
// to render different styles on the client and server, these aren't directly supported in React Native
// but can be achieved using a styling library like Nativewind.
export function useColorScheme() {
  return 'light';
}

================
File: hooks/usePolly.ts
================
import { useCallback } from 'react';
import Polly from '@/services/polly/polly-wrapper';
import { useConversationStore } from '@/src/stores/conversationStore';

export function usePolly() {
  const { 
    setSpeechState, 
    setError,
    speechRate,
    speechVolume
  } = useConversationStore(state => ({
    setSpeechState: state.setSpeechState,
    setError: state.setError,
    speechRate: state.speechRate,
    speechVolume: state.speechVolume
  }));

  const speak = useCallback((text: string, customOptions = {}) => {
    return Polly.speak(text, {
      rate: speechRate,
      volume: speechVolume,
      onStart: () => setSpeechState({ isSpeaking: true }),
      onDone: () => setSpeechState({ isSpeaking: false }),
      onError: (error) => {
        setSpeechState({ isSpeaking: false });
        setError(`Failed to speak: ${error.message}`);
      },
      ...customOptions
    });
  }, [speechRate, speechVolume, setSpeechState, setError]);

  const stop = useCallback(() => {
    Polly.stop();
    setSpeechState({ isSpeaking: false });
  }, [setSpeechState]);

  return { speak, stop };
}

================
File: hooks/useThemeColor.ts
================
/**
 * Learn more about light and dark modes:
 * https://docs.expo.dev/guides/color-schemes/
 */

import { useColorScheme } from 'react-native';

import { Colors } from '@/constants/Colors';

export function useThemeColor(
  props: { light?: string; dark?: string },
  colorName: keyof typeof Colors.light & keyof typeof Colors.dark
) {
  const theme = useColorScheme() ?? 'light';
  const colorFromProps = props[theme];

  if (colorFromProps) {
    return colorFromProps;
  } else {
    return Colors[theme][colorName];
  }
}

================
File: package.json
================
{
  "name": "storywriter",
  "version": "1.0.0",
  "main": "expo-router/entry",
  "scripts": {
    "start": "expo start",
    "android": "expo run:android",
    "ios": "expo run:ios",
    "web": "expo start --web",
    "test": "jest",
    "type-check": "tsc --noEmit",
    "type-check:watch": "tsc --noEmit --watch",
    "lint": "tsc --noEmit && expo lint",
    "validate": "npm run type-check && npm run test"
  },
  "dependencies": {
    "@aws-sdk/client-polly": "^3.758.0",
    "@aws-sdk/client-transcribe-streaming": "^3.750.0",
    "@react-native-async-storage/async-storage": "1.23.1",
    "@react-native-community/slider": "4.5.2",
    "@react-native-voice/voice": "^3.2.4",
    "axios": "^1.7.9",
    "expo": "~52.0.20",
    "expo-build-properties": "~0.13.1",
    "expo-constants": "~17.0.3",
    "expo-dev-client": "~5.0.6",
    "expo-linking": "~7.0.3",
    "expo-router": "~4.0.14",
    "expo-screen-orientation": "~8.0.2",
    "expo-speech": "~13.0.0",
    "expo-splash-screen": "~0.29.18",
    "expo-status-bar": "~2.0.0",
    "expo-web-browser": "~14.0.1",
    "react": "18.3.1",
    "react-dom": "18.3.1",
    "react-native": "0.76.5",
    "react-native-config": "^1.5.5",
    "react-native-dotenv": "^3.4.11",
    "react-native-gesture-handler": "~2.20.2",
    "react-native-reanimated": "~3.16.1",
    "react-native-safe-area-context": "4.12.0",
    "react-native-screens": "~4.1.0",
    "react-native-web": "~0.19.6",
    "zustand": "^5.0.2"
  },
  "devDependencies": {
    "@babel/core": "^7.20.0",
    "@expo/config-plugins": "^9.0.12",
    "@expo/vector-icons": "^14.0.4",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.13.5",
    "@types/prop-types": "^15.7.14",
    "@types/react": "~18.3.12",
    "@types/react-native": "^0.72.8",
    "@types/react-test-renderer": "^19.0.0",
    "babel-plugin-module-resolver": "^5.0.2",
    "jest": "^29.7.0",
    "jest-expo": "^52.0.2",
    "react-test-renderer": "^18.2.0",
    "typescript": "~5.3.3"
  },
  "jest": {
    "preset": "jest-expo",
    "transformIgnorePatterns": [
      "node_modules/(?!((jest-)?react-native|@react-native(-community)?)|expo(nent)?|@expo(nent)?/.*|@expo-google-fonts/.*|react-navigation|@react-navigation/.*|@unimodules/.*|unimodules|sentry-expo|native-base|react-native-svg)"
    ]
  },
  "private": true
}

================
File: README.md
================
# StoryWriter

Create your own digital storybooks with the help of a cyber assistant!

This app is designed for kids to use on a tablet. They can speak with an AI assistant to generate text and images in a storybook display.

## Project Description
This is an [Expo](https://expo.dev) project created with [`create-expo-app`](https://www.npmjs.com/package/create-expo-app).

An active connection to Hugging Face API is required ([https://huggingface.co](https://huggingface.co)). Add a .env file to the root directory with contents: [`HUGGING_FACE_API_KEY=xxxxxx'].

## Get started

1. Install dependencies

   ```bash
   npm install
   ```

2. Start the app

   ```bash
    npx expo start
   ```

## Dev Notes

### Feb 2025
I've enlisted help from my (human) friend Tim, who has worked on a refactor of story.tsx to remove unused sections and focus on getting the initial assistant conversation going. We are working on the `develop` branch.

#### Feb 23
I've added AWS Transcribe to the project on `develop`. You'll need to update `.env` file with these keys:

```
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1
```

### Jan 2025
With the help of Claude AI LLM ([https://claude.ai](https://claude.ai)), I am creating this tablet app for kids. They will be able to speak with an AI assistant to generate text and images in a storybook display. I am learning React Native and Typescript as I go.

My initial vision was to build an app that would self-contain its own LLM, but this proved difficult (app size was just too big), so it now uses an API connection to Hugging Face. Be sure to follow the instructions to enter your API key so this connection will work.

#### Jan 24
Infinite loop is resolved! You can launch the app and click the opening button to start the conversation with the assistant.
Next step is to get the assistant to listen and hear your voice response.

================
File: scripts/reset-project.js
================
#!/usr/bin/env node

/**
 * This script is used to reset the project to a blank state.
 * It moves the /app directory to /app-example and creates a new /app directory with an index.tsx and _layout.tsx file.
 * You can remove the `reset-project` script from package.json and safely delete this file after running it.
 */

const fs = require('fs');
const path = require('path');

const root = process.cwd();
const oldDirPath = path.join(root, 'app');
const newDirPath = path.join(root, 'app-example');
const newAppDirPath = path.join(root, 'app');

const indexContent = `import { Text, View } from "react-native";

export default function Index() {
  return (
    <View
      style={{
        flex: 1,
        justifyContent: "center",
        alignItems: "center",
      }}
    >
      <Text>Edit app/index.tsx to edit this screen.</Text>
    </View>
  );
}
`;

const layoutContent = `import { Stack } from "expo-router";

export default function RootLayout() {
  return (
    <Stack>
      <Stack.Screen name="index" />
    </Stack>
  );
}
`;

fs.rename(oldDirPath, newDirPath, (error) => {
  if (error) {
    return console.error(`Error renaming directory: ${error}`);
  }
  console.log('/app moved to /app-example.');

  fs.mkdir(newAppDirPath, { recursive: true }, (error) => {
    if (error) {
      return console.error(`Error creating new app directory: ${error}`);
    }
    console.log('New /app directory created.');

    const indexPath = path.join(newAppDirPath, 'index.tsx');
    fs.writeFile(indexPath, indexContent, (error) => {
      if (error) {
        return console.error(`Error creating index.tsx: ${error}`);
      }
      console.log('app/index.tsx created.');

      const layoutPath = path.join(newAppDirPath, '_layout.tsx');
      fs.writeFile(layoutPath, layoutContent, (error) => {
        if (error) {
          return console.error(`Error creating _layout.tsx: ${error}`);
        }
        console.log('app/_layout.tsx created.');
      });
    });
  });
});

================
File: services/huggingFaceService.js
================
// services/huggingFaceService.js
import Constants from 'expo-constants';
import axios from 'axios';

const IMAGE_MODEL_URL = 'https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0';

console.log('huggingFace Constants: ', Constants);

const HUGGING_FACE_API_URL = 'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3';
const MAX_RETRIES = 3;
const INITIAL_RETRY_DELAY = 1000;

class HuggingFaceService {
  constructor() {
    
    this.apiKey = Constants.expoConfig.extra.HUGGING_FACE_API_KEY;
    this.client = axios.create({
      baseURL: HUGGING_FACE_API_URL,
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json',
      },
      timeout: 30000, // 30 second timeout
    });
  }

  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  

  async generateResponse(prompt, retryCount = 0) {
    // Add validation for empty/invalid prompts
    if (!prompt || typeof prompt !== 'string' || prompt.trim().length === 0) {
      console.error('Invalid or empty prompt received');
      throw new Error('Invalid prompt');
    }

    // Check if this is an interview prompt without any conversation history
    if (prompt.includes('Based on our conversation so far') && 
        !prompt.includes('user:')) {
      console.log('Preventing API call with empty conversation history');
      return 'What kind of story would you like to create today?';
    }

    try {
      console.log('\n=== API Request ===');
      console.log('Attempt:', retryCount + 1);
      console.log('URL:', HUGGING_FACE_API_URL);
      console.log('API Key (first 8 chars):', this.apiKey?.substring(0, 8));
      
      const formattedPrompt = `<s>[INST] ${prompt} [/INST]`;
      console.log('Formatted Prompt:', formattedPrompt);

      const parameters = {
        max_new_tokens: 2000,
        temperature: 0.7,
        top_p: 0.95,
        do_sample: true,
        return_full_text: false,
        wait_for_model: true,
      };
      
      console.log('Parameters:', parameters);

      const startTime = Date.now();
      
      const response = await this.client.post('', {
        inputs: formattedPrompt,
        parameters,
      });

      const endTime = Date.now();
      
      console.log('\n=== API Response ===');
      console.log('Time taken:', endTime - startTime, 'ms');
      console.log('Status:', response.status);
      console.log('Headers:', response.headers);
      console.log('Full response data:', response.data);

      if (!response.data?.[0]?.generated_text) {
        console.error('Invalid response structure:', response.data);
        throw new Error('Empty or invalid response received');
      }

      const generatedText = response.data[0].generated_text.trim();
      console.log('Generated text:', generatedText);
      
      return generatedText;
    } catch (error) {
      console.error('\n=== API Error ===');
      console.error('Error:', error.message);
      
      if (error.response) {
        console.error('Response status:', error.response.status);
        console.error('Response data:', error.response.data);
        console.error('Response headers:', error.response.headers);
        
        if (error.response.status === 503 && error.response.data?.estimated_time) {
          const waitTime = error.response.data.estimated_time * 1000;
          console.log(`Model is loading. Waiting ${waitTime}ms before retry...`);
          await this.sleep(waitTime);
          if (retryCount < MAX_RETRIES) {
            return this.generateResponse(prompt, retryCount + 1);
          }
        }
      }

      if (retryCount < MAX_RETRIES) {
        const retryDelay = INITIAL_RETRY_DELAY * Math.pow(2, retryCount);
        console.log(`Retrying in ${retryDelay}ms...`);
        await this.sleep(retryDelay);
        return this.generateResponse(prompt, retryCount + 1);
      }

      throw error;
    }
  }
  async generateImage(prompt, retryCount = 0) {
    // Add validation for empty/invalid prompts
    if (!prompt || typeof prompt !== 'string' || prompt.trim().length === 0) {
      console.error('Invalid or empty prompt received');
      throw new Error('Invalid prompt');
    }
  
    try {
      console.log('\n=== Image API Request ===');
      console.log('Attempt:', retryCount + 1);
      console.log('URL:', IMAGE_MODEL_URL);
      console.log('API Key (first 8 chars):', this.apiKey?.substring(0, 8));
      
      const safePrompt = `child-friendly, safe, cartoon style illustration of ${prompt}`;
      console.log('Image Prompt:', safePrompt);
  
      // Create a new image-specific client
      const imageClient = axios.create({
        baseURL: IMAGE_MODEL_URL,
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        timeout: 60000, // 60 second timeout for image generation
        responseType: 'arraybuffer', // Important for receiving binary data
      });
  
      const startTime = Date.now();
      
      const response = await imageClient.post('', {
        inputs: safePrompt,
        options: {
          wait_for_model: true
        }
      });
  
      const endTime = Date.now();
      
      console.log('\n=== Image API Response ===');
      console.log('Time taken:', endTime - startTime, 'ms');
      console.log('Status:', response.status);
      console.log('Headers:', response.headers);
  
      // Convert binary data to base64 without using Buffer
      // We'll use browser APIs instead
      const arrayBuffer = response.data;
      
      // Create a binary string from the array buffer
      let binary = '';
      const bytes = new Uint8Array(arrayBuffer);
      const len = bytes.byteLength;
      for (let i = 0; i < len; i++) {
        binary += String.fromCharCode(bytes[i]);
      }
      
      // Convert binary to base64 using btoa (built into browsers & React Native)
      const base64 = btoa(binary);
      
      // Create data URI
      const imageUri = `data:image/jpeg;base64,${base64}`;
      
      console.log('Image generated with URI length:', imageUri.length);
      
      return imageUri;
    } catch (error) {
      console.error('\n=== Image API Error ===');
      console.error('Error:', error.message);
      
      if (error.response) {
        console.error('Response status:', error.response.status);
        
        // Handle the model loading case
        if (error.response.status === 503 && error.response.data?.estimated_time) {
          const waitTime = error.response.data.estimated_time * 1000;
          console.log(`Model is loading. Waiting ${waitTime}ms before retry...`);
          await this.sleep(waitTime);
          if (retryCount < MAX_RETRIES) {
            return this.generateImage(prompt, retryCount + 1);
          }
        }
      }
  
      if (retryCount < MAX_RETRIES) {
        const retryDelay = INITIAL_RETRY_DELAY * Math.pow(2, retryCount);
        console.log(`Retrying in ${retryDelay}ms...`);
        await this.sleep(retryDelay);
        return this.generateImage(prompt, retryCount + 1);
      }
  
      throw error;
    }
  }
}

export default new HuggingFaceService();

================
File: services/polly/index.ts
================
import { Platform } from 'react-native';
import { PollyServiceInterface } from './types';
import WebPollyService from './web';
import NativePollyService from './native';

const PollyService: PollyServiceInterface = 
  Platform.select({
    web: () => WebPollyService,
    default: () => NativePollyService,
  })();

export default PollyService;

================
File: services/polly/native.ts
================
import { PollyServiceInterface, PollyOptions } from './types';

class NativePollyService implements PollyServiceInterface {
  async synthesizeSpeech(text: string, options?: PollyOptions): Promise<string> {
    console.warn('Native Polly implementation not yet available');
    throw new Error('Native Polly implementation not yet available');
  }

  async speak(text: string, options?: PollyOptions): Promise<void> {
    console.warn('Native Polly implementation not yet available');
    throw new Error('Native Polly implementation not yet available');
  }

  async stop(): Promise<void> {
    console.warn('Native Polly implementation not yet available');
  }
}

export default new NativePollyService();

================
File: services/polly/polly-wrapper.ts
================
import PollyService from './index';

// Define types for the options
type SpeakOptions = {
  voice?: string;
  engine?: 'standard' | 'neural';
  rate?: number;
  volume?: number;
  onStart?: () => void;
  onDone?: () => void;
  onError?: (error: Error) => void;
};

const Polly = {
  speak: async (text: string, options: SpeakOptions = {}) => {
    try {
      const defaultOptions = {
        voice: 'Kendra',
        engine: 'neural' as const,
        rate: 1.0,
        volume: 1.0,
        onStart: () => {},
        onDone: () => {},
        onError: (error: Error) => { console.error(error); }
      };
      
      // Combine default options with provided options
      const mergedOptions = { ...defaultOptions, ...options };
      
      return await PollyService.speak(text, mergedOptions);
    } catch (error) {
      console.error('Polly speak error:', error);
      if (options.onError) {
        options.onError(error instanceof Error ? error : new Error(String(error)));
      }
    }
  },
  
  stop: async () => {
    try {
      await PollyService.stop();
    } catch (error) {
      console.error('Polly stop error:', error);
    }
  }
};

export default Polly;

================
File: services/polly/types.ts
================
export interface PollyServiceInterface {
    synthesizeSpeech: (text: string, options?: PollyOptions) => Promise<string>;
    speak: (text: string, options?: PollyOptions) => Promise<void>;
    stop: () => Promise<void>;
  }
  
  export interface PollyOptions {
    voice?: string;
    engine?: 'standard' | 'neural';
    rate?: number;
    pitch?: number;
    volume?: number;
    onStart?: () => void;
    onDone?: () => void;
    onError?: (error: Error) => void;
  }

================
File: services/polly/web.ts
================
import { 
    PollyClient, 
    SynthesizeSpeechCommand,
    Engine,
    OutputFormat,
    TextType,
    VoiceId
  } from "@aws-sdk/client-polly";
  import Constants from 'expo-constants';
  import { PollyServiceInterface, PollyOptions } from './types';
  
  class PollyService implements PollyServiceInterface {
    private client: PollyClient;
    private audio: HTMLAudioElement | null = null;
  
    constructor() {
      this.client = new PollyClient({
        region: Constants.expoConfig?.extra?.AWS_REGION || 'us-east-1',
        credentials: {
          accessKeyId: Constants.expoConfig?.extra?.AWS_ACCESS_KEY_ID || '',
          secretAccessKey: Constants.expoConfig?.extra?.AWS_SECRET_ACCESS_KEY || ''
        }
      });
    }
  
    async synthesizeSpeech(text: string, options?: PollyOptions): Promise<string> {
      try {
        const params = {
          Text: text,
          OutputFormat: OutputFormat.MP3,
          VoiceId: (options?.voice || VoiceId.Kendra) as VoiceId,
          Engine: options?.engine || 'neural',
          TextType: TextType.TEXT
        };
  
        const command = new SynthesizeSpeechCommand(params);
        const response = await this.client.send(command);
  
        if (!response.AudioStream) {
          throw new Error('No audio stream returned from Polly');
        }
  
        // Convert the binary audio stream to a blob URL
        const blob = new Blob([await response.AudioStream.transformToByteArray()], { type: 'audio/mpeg' });
        const url = URL.createObjectURL(blob);
        return url;
      } catch (error) {
        console.error('Failed to synthesize speech:', error);
        throw error;
      }
    }
  
    async speak(text: string, options?: PollyOptions): Promise<void> {
      try {
        if (options?.onStart) {
          options.onStart();
        }
  
        const audioUrl = await this.synthesizeSpeech(text, options);
        
        // Stop any existing audio
        await this.stop();
        
        // Create and play audio
        this.audio = new Audio(audioUrl);
        this.audio.volume = options?.volume || 1.0;
        this.audio.playbackRate = options?.rate || 1.0;
        
        this.audio.onended = () => {
          if (options?.onDone) {
            options.onDone();
          }
          // Clean up the URL object
          URL.revokeObjectURL(audioUrl);
        };
        
        this.audio.onerror = (e) => {
          if (options?.onError) {
            options.onError(new Error(`Audio playback error: ${e}`));
          }
          URL.revokeObjectURL(audioUrl);
        };
        
        await this.audio.play();
      } catch (error) {
        console.error('Failed to play speech:', error);
        if (options?.onError) {
          options.onError(error as Error);
        }
        throw error;
      }
    }
  
    async stop(): Promise<void> {
      if (this.audio) {
        this.audio.pause();
        this.audio.currentTime = 0;
        this.audio = null;
      }
    }
  }
  
  export default new PollyService();

================
File: services/transcribe/index.ts
================
import { Platform } from 'react-native';
import { TranscribeServiceInterface } from './types';
import WebTranscribeService from './web';
import NativeTranscribeService from './native';

const TranscribeService: TranscribeServiceInterface = 
  Platform.select({
    web: () => WebTranscribeService,
    default: () => NativeTranscribeService,
  })();

export default TranscribeService;

================
File: services/transcribe/native.ts
================
// Will create later for iPad/Android
import { Platform } from 'react-native';
import { TranscribeServiceInterface } from './types';

================
File: services/transcribe/types.ts
================
export interface TranscribeServiceInterface {
    startTranscription: (onTranscript: (text: string) => void) => Promise<void>;
    stopTranscription: () => Promise<void>;
    isTranscribing: () => boolean;
  }

================
File: services/transcribe/web.ts
================
import { 
  TranscribeStreamingClient,
  StartStreamTranscriptionCommand,
  StartStreamTranscriptionCommandInput,
  TranscriptEvent,
  AudioStream
} from "@aws-sdk/client-transcribe-streaming";
import Constants from 'expo-constants';
import { TranscribeServiceInterface } from './types';

// temporary
import Config from 'react-native-config';

console.log('Constants Imported from expo-constants: ', Constants);

console.log('Constants.expoConfig: ', Constants.expoConfig);


class ChromeTestTranscribeService implements TranscribeServiceInterface {
  private client: TranscribeStreamingClient;
  private mediaRecorder: MediaRecorder | null = null;
  private stream: MediaStream | null = null;
  private _isTranscribing: boolean = false;
  private audioContext: AudioContext | null = null;
  private audioProcessor: ScriptProcessorNode | null = null;
  private audioChunks: Uint8Array[] = [];
  private readonly SAMPLE_RATE = 16000;
  private readonly CHUNK_SIZE = 4096;

  constructor() {
    console.warn('ChromeTestTranscribeService: This is a test implementation for Chrome browser only.');

   console.log('Config: ', Config.AWS_ACCESS_KEY_ID);

    this.client = new TranscribeStreamingClient({
      region: Constants.expoConfig?.extra?.AWS_REGION || 'us-east-1',
      credentials: {
        accessKeyId: Constants.expoConfig?.extra?.AWS_ACCESS_KEY_ID || '',
        secretAccessKey: Constants.expoConfig?.extra?.AWS_SECRET_ACCESS_KEY || ''
      }
    });

    // Debug AWS configuration
    console.log('AWS Config:', {
      region: Constants.expoConfig?.extra?.AWS_REGION,
      hasAccessKey: !!Constants.expoConfig?.extra?.AWS_ACCESS_KEY_ID,
      hasSecretKey: !!Constants.expoConfig?.extra?.AWS_SECRET_ACCESS_KEY
    });
  }

  private isChromeEnvironment(): boolean {
    const isChrome = /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
    if (!isChrome) {
      console.error('ChromeTestTranscribeService: This service only works in Chrome browser.');
    }
    return isChrome;
  }

  private async setupAudioCapture(): Promise<MediaStream> {
    if (!this.isChromeEnvironment()) {
      throw new Error('This test implementation only works in Chrome browser');
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: this.SAMPLE_RATE,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      return stream;
    } catch (error) {
      console.error('TEST MODE - Microphone Error:', error);
      throw new Error('Microphone access failed in test mode');
    }
  }

  private async setupAudioProcessing(stream: MediaStream) {
    try {
      // Initialize Web Audio API components
      this.audioContext = new AudioContext({
        sampleRate: this.SAMPLE_RATE,
        latencyHint: 'interactive'
      });
      
      const source = this.audioContext.createMediaStreamSource(stream);
      this.audioProcessor = this.audioContext.createScriptProcessor(
        this.CHUNK_SIZE, // Buffer size
        1, // Input channels
        1  // Output channels
      );

      console.log('TEST MODE - Audio processing setup:', {
        sampleRate: this.audioContext.sampleRate,
        bufferSize: this.CHUNK_SIZE
      });

      // Process audio data
      this.audioProcessor.onaudioprocess = (e) => {
        if (!this._isTranscribing) return;

        const inputData = e.inputBuffer.getChannelData(0);
        
        // Debug audio levels
        const audioLevel = Math.max(...inputData.map(Math.abs));
        if (audioLevel > 0.01) {  // Only log when there's significant audio
          console.log('TEST MODE - Audio level:', audioLevel.toFixed(3));
        }
        
        // Convert Float32Array to Int16Array (AWS Transcribe format)
        const audioData = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          // Scale and clamp the audio samples
          const s = Math.max(-1, Math.min(1, inputData[i]));
          audioData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }

        // Debug chunk size
        console.log('TEST MODE - Created audio chunk:', audioData.length, 'samples');

        // Push the processed audio chunk
        this.audioChunks.push(new Uint8Array(audioData.buffer));
        console.log('TEST MODE - Audio chunks buffer size:', this.audioChunks.length);
      };

      // Connect the audio nodes
      source.connect(this.audioProcessor);
      this.audioProcessor.connect(this.audioContext.destination);

      console.log('TEST MODE - Audio processing pipeline established');
    } catch (error) {
      console.error('TEST MODE - Audio processing setup error:', error);
      throw error;
    }
  }

  async startTranscription(onTranscript: (text: string) => void): Promise<void> {
    console.log('TEST MODE - Starting transcription in Chrome test environment');
    
    if (!this.isChromeEnvironment()) return;

    if (this._isTranscribing) {
      console.warn('TEST MODE - Transcription already in progress');
      return;
    }

    try {
      this._isTranscribing = true;
      this.stream = await this.setupAudioCapture();
      await this.setupAudioProcessing(this.stream);

      // Create an async generator for audio streaming
      const audioStreamGenerator = async function* (this: ChromeTestTranscribeService) {
        console.log('TEST MODE - Starting audio stream');
        let chunkCount = 0;
        
        while (this._isTranscribing) {
          if (this.audioChunks.length > 0) {
            const chunk = this.audioChunks.shift();
            if (chunk) {
              chunkCount++;
              console.log('TEST MODE - Sending chunk #', chunkCount, 'to AWS');
              yield { AudioEvent: { AudioChunk: chunk } } as AudioStream;
            }
          }
          await new Promise(resolve => setTimeout(resolve, 20)); // Reduced delay for smoother streaming
        }
      }.bind(this);

      const params: StartStreamTranscriptionCommandInput = {
        LanguageCode: 'en-US',
        MediaEncoding: 'pcm',
        MediaSampleRateHertz: this.SAMPLE_RATE,
        AudioStream: audioStreamGenerator(),
        EnablePartialResultsStabilization: true,
        PartialResultsStability: 'high',
        ShowSpeakerLabel: false // Control speaker identification
      };

      console.log('TEST MODE - Starting AWS Transcribe streaming with params:', params);

      const command = new StartStreamTranscriptionCommand(params);
      const response = await this.client.send(command);

      console.log('TEST MODE - AWS Response:', response);
      
      if (!response.TranscriptResultStream) {
        console.error('TEST MODE - No TranscriptResultStream in response');
        return;
      }

      try {
        for await (const event of response.TranscriptResultStream) {
          console.log('TEST MODE - Raw stream event:', JSON.stringify(event, null, 2));
          
          // AWS Transcribe events come in a specific shape
          const transcriptEvent = event as TranscriptEvent;
          
          if (!transcriptEvent.TranscriptEvent?.Transcript) {
            console.log('TEST MODE - No transcript in event');
            continue;
          }

          const results = transcriptEvent.TranscriptEvent.Transcript.Results;
          if (!results || results.length === 0) {
            console.log('TEST MODE - No results in transcript');
            continue;
          }

          // Log the full results for debugging
          console.log('TEST MODE - Full results:', JSON.stringify(results, null, 2));

          // Get the transcript from the first result's first alternative
          const result = results[0];
          if (result.IsPartial === false && result.Alternatives && result.Alternatives.length > 0) {
            const transcript = result.Alternatives[0].Transcript;
            if (transcript) {
              console.log('TEST MODE - Final transcript received:', transcript);
              onTranscript(transcript.trim());
            }
          }
        }
      } catch (streamError) {
        console.error('TEST MODE - Error processing stream:', streamError);
        throw streamError;
      }
    } catch (error) {
      console.error('TEST MODE - Transcription error:', error);
      await this.stopTranscription();
      throw error;
    }
  }

  async stopTranscription(): Promise<void> {
    console.log('TEST MODE - Stopping transcription');
    
    try {
      this._isTranscribing = false;

      // Clean up audio processing
      if (this.audioProcessor) {
        this.audioProcessor.disconnect();
        this.audioProcessor = null;
      }

      if (this.audioContext) {
        await this.audioContext.close();
        this.audioContext = null;
      }

      // Clean up media resources
      if (this.stream) {
        this.stream.getTracks().forEach(track => track.stop());
        this.stream = null;
      }

      this.audioChunks = [];
      console.log('TEST MODE - Cleanup completed');
    } catch (error) {
      console.error('TEST MODE - Error stopping:', error);
      throw error;
    }
  }

  isTranscribing(): boolean {
    return this._isTranscribing;
  }
}

export default new ChromeTestTranscribeService();

================
File: src/data/storyData.ts
================
export const questions = [
    "What's the name of your superhero?",
    "What special power does your superhero have?",
    "Where does your superhero live?",
    "Who is your superhero's best friend?",
    "What's the biggest problem your superhero needs to solve?"
  ];
  
  export const placeholderMapping = {
    "What's the name of your superhero?": "hero",
    "What special power does your superhero have?": "power",
    "Where does your superhero live?": "setting",
    "Who is your superhero's best friend?": "friend",
    "What's the biggest problem your superhero needs to solve?": "problem"
  };
  
  export interface StoryTemplate {
    title: string;
    pages: string[];
  }
  
  export const storyTemplates: StoryTemplate[] = [
    {
      title: "The Hero's Journey",
      pages: [
        "In the bustling city of {setting}, there lived an ordinary person named {hero}. Little did they know, their life was about to change forever.",
        "One day, {hero} discovered they had the incredible power to {power}. At first, they were scared and confused by this newfound ability.",
        "Luckily, {hero}'s best friend, {friend}, was there to help. Together, they learned to control and understand the new power.",
        "But trouble was brewing in {setting}. A terrible problem arose: {problem}. The city needed a hero more than ever!",
        "{hero} knew they had to act. Using their power to {power}, they faced the challenge head-on, determined to save their home.",
        "The battle was tough, but {hero} remembered the support of {friend} and found the strength to keep going, no matter how hard it got.",
        "In a final, epic confrontation, {hero} used their powers in a way they never had before, pushing themselves to the limit.",
        "Victory! {hero} had saved the day. The people of {setting} cheered for their new superhero, grateful for their bravery.",
        "From that day on, {hero} vowed to use their powers to protect {setting} and help those in need, always remembering the importance of friendship and courage.",
        "And so began the legend of {hero}, the superhero who could {power}, ready to face whatever challenges may come their way."
      ]
    },
    // You can add more story templates here
  ];

================
File: src/stores/conversationStore.ts
================
import { create } from 'zustand';
import { devtools } from 'zustand/middleware';
import AsyncStorage from '@react-native-async-storage/async-storage';
import { StoryPage } from '@/src/utils/storyGenerator';

// Define all possible states of our conversation
export type ConversationPhase = 
  | 'INITIAL'           // Just started, no interaction yet
  | 'INTERVIEWING'      // Actively asking questions
  | 'PROCESSING'        // Processing user's response
  | 'GENERATING_STORY'  // Creating the story
  | 'DISPLAYING_STORY'; // Showing the generated story

// Define the structure of our conversation turns
export interface ConversationTurn {
  role: 'system' | 'user' | 'assistant';
  content: string;
  timestamp: number;
}

// Define what a saved story looks like
export interface SavedStory {
  id: string;           // Unique identifier for the story
  title: string;        // Display title
  content: StoryPage[]; // The actual story pages
  elements: StoryElements; // The gathered story elements
  createdAt: number;    // Timestamp for sorting
}

// Define story elements structure
export interface StoryElements {
  [key: string]: string;
}

// Define what information we need to track about speech
export interface SpeechState {
  isListening: boolean;
  isSpeaking: boolean;
  speechRate: number;
  speechVolume: number;
}

// Define our story state
export interface StoryState {
  currentPageIndex: number;
  storyPages: StoryPage[];
  storyElements: StoryElements;
  savedStories: SavedStory[];
}

// Define our complete store state shape
export interface ConversationState extends SpeechState, StoryState {
  phase: ConversationPhase;
  conversationHistory: ConversationTurn[];
  currentQuestion: string;
  error: string | null;
  
  // Story management actions
  setStoryPages: (pages: StoryPage[]) => void;
  setCurrentPage: (index: number) => void;
  nextPage: () => void;
  previousPage: () => void;
  updateStoryElements: (elements: StoryElements) => void;
  saveStory: (title?: string) => Promise<void>;
  loadStory: (id: string) => Promise<void>;
  loadSavedStories: () => Promise<void>;
  
  // Existing conversation actions
  startConversation: () => void;
  addUserResponse: (response: string) => void;
  setQuestion: (question: string) => void;
  setPhase: (phase: ConversationPhase) => void;
  setSpeechState: (speechState: Partial<SpeechState>) => void;
  resetConversation: () => void;
  setError: (error: string | null) => void;
}

const useConversationStore = create<ConversationState>()(
  devtools(
    (set, get) => ({
      phase: 'INITIAL',
      conversationHistory: [],
      currentQuestion: '',
      error: null,
      isListening: false,
      isSpeaking: false,
      speechRate: 1.0,
      speechVolume: 1.0,
      currentPageIndex: 0,
      storyPages: [],
      storyElements: {},
      savedStories: [],
      
      // Actions are simplified to avoid nested updates
      startConversation: () => {
        set({
          phase: 'INTERVIEWING',
          conversationHistory: [{
            role: 'system',
            content: 'You are a friendly children\'s story creator assistant.',
            timestamp: Date.now()
          }],
          currentQuestion: 'What kind of story would you like to create today?',
          error: null,
          isListening: false,
          isSpeaking: false
        });
      },

      addUserResponse: (response: string) => {
        const { conversationHistory, phase } = get();
        
        // Only add response if we're in the right phase
        if (phase !== 'INTERVIEWING' && phase !== 'PROCESSING') {
          console.warn('Attempted to add user response in invalid phase:', phase);
          return;
        }

        set({
          conversationHistory: [
            ...conversationHistory,
            {
              role: 'user',
              content: response,
              timestamp: Date.now()
            }
          ],
          phase: 'PROCESSING'
        });
      },

      setQuestion: (question: string) => {
        const { conversationHistory } = get();
        
        set({
          currentQuestion: question,
          conversationHistory: [
            ...conversationHistory,
            {
              role: 'assistant',
              content: question,
              timestamp: Date.now()
            }
          ],
          phase: 'INTERVIEWING'
        });
      },

      setPhase: (phase: ConversationPhase) => {
        set({ phase });
      },

      setSpeechState: (speechState: Partial<SpeechState>) => {
        set((state) => ({
          ...state,
          ...speechState
        }));
      },

      resetConversation: () => {
        set({
          phase: 'INITIAL',
          conversationHistory: [],
          currentQuestion: '',
          error: null,
          isListening: false,
          isSpeaking: false
        });
      },

      setError: (error: string | null) => {
        set({ error });
      },
      // Story management actions
      setStoryPages: (pages: StoryPage[]) => {
        set({
          storyPages: pages,
          currentPageIndex: 0,  // Reset to first page when setting new pages
          phase: 'DISPLAYING_STORY'
        });
      },

      setCurrentPage: (index: number) => {
        const { storyPages } = get();
        if (index >= 0 && index < storyPages.length) {
          set({ currentPageIndex: index });
        }
      },

      nextPage: () => {
        const { currentPageIndex, storyPages } = get();
        if (currentPageIndex < storyPages.length - 1) {
          set({ currentPageIndex: currentPageIndex + 1 });
        }
      },

      previousPage: () => {
        const { currentPageIndex } = get();
        if (currentPageIndex > 0) {
          set({ currentPageIndex: currentPageIndex - 1 });
        }
      },

      updateStoryElements: (elements: StoryElements) => {
        set({ storyElements: elements });
      },

      saveStory: async (title?: string) => {
        const { storyPages, storyElements, savedStories } = get();
        
        if (storyPages.length === 0) {
          throw new Error('No story to save');
        }

        const newStory: SavedStory = {
          id: Date.now().toString(),
          title: title || `Story Created on ${new Date().toLocaleDateString()}`,
          content: storyPages,
          elements: storyElements,
          createdAt: Date.now()
        };

        const updatedStories = [...savedStories, newStory];
        
        try {
          await AsyncStorage.setItem('savedStories', JSON.stringify(updatedStories));
          set({ savedStories: updatedStories });
        } catch (error) {
          console.error('Failed to save story:', error);
          throw new Error('Failed to save story');
        }
      },

      loadStory: async (id: string) => {
        const { savedStories } = get();
        const story = savedStories.find(s => s.id === id);
        
        if (!story) {
          throw new Error('Story not found');
        }

        set({
          storyPages: story.content,
          storyElements: story.elements,
          currentPageIndex: 0,
          phase: 'DISPLAYING_STORY'
        });
      },

      loadSavedStories: async () => {
        try {
          const stored = await AsyncStorage.getItem('savedStories');
          if (stored) {
            const stories = JSON.parse(stored);
            set({ savedStories: stories });
          }
        } catch (error) {
          console.error('Failed to load saved stories:', error);
          throw new Error('Failed to load saved stories');
        }
      }
    })
  )
);

export { useConversationStore };

================
File: src/utils/storyGenerator.ts
================
import { StoryTemplate } from '../data/storyData';

interface StoryElements {
  [key: string]: string;
}

export interface StoryPage {
  textContent: string;
  imageUrl: string;
}

export function generateStory(
  templates: StoryTemplate[],
  elements: StoryElements,
  placeholderMapping: { [key: string]: string }
): StoryPage[] {
  const template = templates[Math.floor(Math.random() * templates.length)];
  
  return template.pages.map(page => {
    let pageContent = page;
    for (let [question, answer] of Object.entries(elements)) {
      const placeholder = placeholderMapping[question];
      if (placeholder) {
        pageContent = pageContent.replace(new RegExp(`{${placeholder}}`, 'g'), answer);
      }
    }
    
    return {
      textContent: pageContent,
      imageUrl: generateImage(pageContent) // This function should be implemented
    };
  });
}

function generateImage(prompt: string): string {
  // In a real application, this would call an image generation API
  // For now, we'll use a placeholder image service
  return `https://via.placeholder.com/300x200?text=${encodeURIComponent(prompt.substring(0, 30))}`;
}

================
File: tsconfig.json
================
{
  "extends": "expo/tsconfig.base",
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true,
    "baseUrl": ".",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "typeRoots": [
      "./node_modules/@types"
    ],
    "types": ["node", "jest", "prop-types"]
  },
  "include": [
    "**/*.ts",
    "**/*.tsx"
  ]
}

================
File: types/env.d.ts
================
declare module '@env' {
    export const HUGGING_FACE_API_KEY: string;
    export const AWS_ACCESS_KEY_ID: string;
    export const AWS_SECRET_ACCESS_KEY: string;
    export const AWS_REGION: string;
  }



================================================================
End of Codebase
================================================================
